---
title: Feature Scaling y Anti-Leakage Pipeline â€” Escalado Ã©tico, reproducible y sin fuga de informaciÃ³n
date: 2025-09-17
---

## Contexto

El dataset **Ames Housing (Iowa)** incluye mÃ¡s de 80 variables que describen propiedades inmobiliarias (dimensiones, materiales, ubicaciÃ³n y precio).  
Su riqueza y complejidad lo hacen ideal para estudiar los efectos del **escalado de variables**, la **presencia de outliers estructurales** y el **riesgo de data leakage**, un error comÃºn que ocurre al transformar datos antes del *split* entre entrenamiento y prueba.

Esta prÃ¡ctica se centra en la **implementaciÃ³n de un pipeline anti-leakage**, comparando distintos mÃ©todos de escalado y evaluando cÃ³mo las transformaciones afectan la distribuciÃ³n de las variables y la validez del modelo.

---

## Objetivos

- Detectar variables numÃ©ricas con escalas desbalanceadas o sesgos extremos.  
- Comparar los mÃ©todos `StandardScaler`, `MinMaxScaler` y `RobustScaler`.  
- Evaluar el impacto del *log transform* en variables fuertemente asimÃ©tricas.  
- DiseÃ±ar un pipeline reproducible que evite *data leakage*.  
- Reflexionar sobre las implicancias Ã©ticas y tÃ©cnicas del preprocesamiento.

---

## Desarrollo

El anÃ¡lisis se organizÃ³ en seis etapas principales:

1. **ExploraciÃ³n inicial:** anÃ¡lisis estadÃ­stico y visual de las escalas de las variables mÃ¡s relevantes.  
2. **SelecciÃ³n de columnas:** se priorizaron `SalePrice`, `LotArea`, `GrLivArea`, `TotalBsmtSF`, `GarageArea` y `YearBuilt`.  
3. **TransformaciÃ³n logarÃ­tmica:** aplicada a columnas con sesgo positivo pronunciado.  
4. **ComparaciÃ³n de mÃ©todos de escalado:** `StandardScaler`, `MinMaxScaler` y `RobustScaler`.  
5. **Pipeline anti-leakage:** implementaciÃ³n reproducible y libre de contaminaciÃ³n entre *train* y *test*.  
6. **EvaluaciÃ³n de resultados y documentaciÃ³n:** visualizaciones, mÃ©tricas y reflexiones crÃ­ticas.

---

## Evidencias y Resultados

### DistribuciÃ³n de variables numÃ©ricas (escala logarÃ­tmica)**  

**ObservaciÃ³n tÃ©cnica:**  
El grÃ¡fico muestra una diferencia de hasta tres Ã³rdenes de magnitud entre `LotArea`, `GrLivArea` y `SalePrice`, con dispersiÃ³n muy superior al resto.

**InterpretaciÃ³n analÃ­tica:**  
Estas variables dominan el rango numÃ©rico y pueden â€œarrastrarâ€ a las demÃ¡s en algoritmos basados en distancia (KNN, SVM).  
`YearBuilt`, en cambio, mantiene una escala mucho mÃ¡s compacta, sin requerir ajuste.

**ReflexiÃ³n metodolÃ³gica:**  
El escalado no es opcional: sin Ã©l, las mÃ©tricas de distancia se vuelven arbitrarias y las correlaciones se distorsionan.

---

### Ratios max/min por variable**  


**ObservaciÃ³n tÃ©cnica:**  
`LotArea` alcanza un ratio de â‰ˆ165 y `SalePrice` â‰ˆ60. Estas relaciones desbalanceadas confirman la necesidad de normalizar.

**InterpretaciÃ³n analÃ­tica:**  
Un rango tan amplio implica que una variaciÃ³n mÃ­nima en una variable pequeÃ±a podrÃ­a ser ignorada por completo durante el entrenamiento.  

**ReflexiÃ³n metodolÃ³gica:**  
El ratio *max/min* es un indicador simple pero potente de inequidad de escala: si supera 50, el escalado deberÃ­a ser obligatorio.

---

### Distribuciones individuales de variables sesgadas**  


**ObservaciÃ³n tÃ©cnica:**  
Las variables `LotArea`, `SalePrice` y `GrLivArea` presentan distribuciones con colas largas hacia la derecha (*right-skew*).  

**InterpretaciÃ³n analÃ­tica:**  
Estos sesgos indican presencia de valores atÃ­picos, aunque probablemente **estructurales** (casas grandes o lujosas).  

**ReflexiÃ³n metodolÃ³gica:**  
Eliminar estos puntos serÃ­a una pÃ©rdida de informaciÃ³n. La soluciÃ³n mÃ¡s Ã©tica y tÃ©cnica es usar un **transformador robusto o logarÃ­tmico** para reducir su impacto sin censurarlos.

---

### **Escalas en TRAIN (log-scale)**  

**ObservaciÃ³n tÃ©cnica:**  
El anÃ¡lisis se aplica solo al conjunto de entrenamiento. Las escalas mantienen su coherencia sin incluir datos de validaciÃ³n.

**InterpretaciÃ³n analÃ­tica:**  
Esto garantiza que las transformaciones no â€œveanâ€ datos futuros, preservando la independencia entre *train* y *test*.

**ReflexiÃ³n metodolÃ³gica:**  
Separar los conjuntos antes de transformar es esencial para evitar *data leakage*, una prÃ¡ctica Ã©ticamente necesaria para resultados confiables.

---

### **Distribuciones antes y despuÃ©s del escalado**  

**ObservaciÃ³n tÃ©cnica:**  
El `StandardScaler` centra la media pero amplifica outliers, el `MinMaxScaler` reduce el rango pero mantiene el sesgo, y el `RobustScaler` logra la mayor estabilidad.

**InterpretaciÃ³n analÃ­tica:**  
Las diferencias visuales demuestran cÃ³mo cada mÃ©todo responde a la presencia de colas largas.  
`RobustScaler` reduce la varianza sin alterar la estructura de la distribuciÃ³n.

**ReflexiÃ³n metodolÃ³gica:**  
Elegir el *scaler* no es una cuestiÃ³n estÃ©tica: implica definir quÃ© estadÃ­stico (media, rango o mediana) representa mejor a la poblaciÃ³n.

---

### **Efecto del Log Transform**  

**ObservaciÃ³n tÃ©cnica:**  
Tras aplicar `np.log1p()` sobre `LotArea`, el *skewness* bajÃ³ de 2.9 a 0.28 y la curtosis se normalizÃ³.

**InterpretaciÃ³n analÃ­tica:**  
La variable deja de concentrar la varianza en pocos valores altos, y la dispersiÃ³n se vuelve mÃ¡s simÃ©trica y manejable.

**ReflexiÃ³n metodolÃ³gica:**  
El orden correcto de transformaciones **Log â†’ Scale** reduce errores de redondeo y produce resultados mÃ¡s reproducibles en pipelines.

---

### **CorrelaciÃ³n original vs escalada**  

**ObservaciÃ³n tÃ©cnica:**  
Las correlaciones lineales permanecen casi inalteradas tras el escalado.

**InterpretaciÃ³n analÃ­tica:**  
Los *scalers* ajustan la magnitud pero no la relaciÃ³n entre variables, confirmando que la estructura del dataset se preserva.

**ReflexiÃ³n metodolÃ³gica:**  
Un buen escalado debe cambiar la escala, no el sentido de la informaciÃ³n.  
Esta evidencia valida que el pipeline respeta la integridad de los datos.

---

### **RelaciÃ³n entre Ã¡rea y precio (antes y despuÃ©s del log)**  

**ObservaciÃ³n tÃ©cnica:**  
El logaritmo de `GrLivArea` y `SalePrice` genera una nube mÃ¡s compacta y lineal.

**InterpretaciÃ³n analÃ­tica:**  
La linealizaciÃ³n mejora la capacidad de ajuste del modelo, especialmente para regresiÃ³n lineal o Ridge/Lasso.

**ReflexiÃ³n metodolÃ³gica:**  
El *log transform* reduce el peso de los valores extremos y mejora la interpretabilidad de la relaciÃ³n Ã¡rea-precio.

---

### ComparaciÃ³n de mÃ©todos de escalado**  

| MÃ©todo | Leakage | RÂ² | MAE | Observaciones |
|---------|----------|------|------|---------------|
| **Con leakage** | âŒ | 0.92 | 14.5k | MÃ©tricas infladas por contaminaciÃ³n del test set. |
| **Sin leakage** | âœ… | 0.82 | 17.8k | Resultados realistas, dependientes del orden manual. |
| **Pipeline anti-leakage** | âœ… | 0.83 | 17.6k | Reproducible, estable y Ã©ticamente correcto. |

**ObservaciÃ³n tÃ©cnica:**  
El pipeline automatizado produce mÃ©tricas coherentes y reproducibles.

**InterpretaciÃ³n analÃ­tica:**  
El leve descenso del RÂ² (de 0.92 a 0.83) no representa una pÃ©rdida, sino la eliminaciÃ³n del sesgo inducido por *leakage*.  

**ReflexiÃ³n metodolÃ³gica:**  
El pipeline garantiza integridad, evita errores humanos y asegura que las mÃ©tricas reflejen la verdadera capacidad predictiva del modelo.

---

## Conclusiones

- Las variables `LotArea` y `GrLivArea` fueron las principales fuentes de distorsiÃ³n en las distancias numÃ©ricas.  
- `RobustScaler` resultÃ³ el mÃ©todo mÃ¡s apropiado por su resistencia a *outliers* estructurales.  
- El orden **Log â†’ Scale** mejora la normalidad de las distribuciones y la estabilidad numÃ©rica.  
- El pipeline anti-leakage asegura reproducibilidad y trazabilidad, evitando contaminaciÃ³n de datos.  
- Las mÃ©tricas sin leakage son mÃ¡s bajas, pero **honestas y generalizables**.

 El proceso de *feature scaling* y diseÃ±o del pipeline permitiÃ³ confirmar de manera empÃ­rica varios principios clave de la ingenierÃ­a de datos moderna:

---

## ReflexiÃ³n final

- **Limitaciones:** las conclusiones dependen del tipo de modelo. Los efectos del escalado pueden variar en Ã¡rboles de decisiÃ³n o redes neuronales.  
- **Decisiones discutibles:** mantener outliers estructurales mejora la generalizaciÃ³n, pero puede afectar mÃ©tricas locales.  
- **Mejoras futuras:** explorar `PowerTransformer` o `QuantileTransformer`, agrupar columnas por tipo y evaluar mÃ©tricas no lineales.  
- **Ã‰tica del preprocesamiento:** evitar *data leakage* no solo mejora la calidad tÃ©cnica, sino que respeta los principios de transparencia y veracidad de los resultados.  

> *El rigor tÃ©cnico sin Ã©tica es solo automatizaciÃ³n de errores.*

---

## Notebook en Google Colab

ğŸ““El notebook completo con el desarrollo de esta prÃ¡ctica puede consultarse en el siguiente enlace:  
[**ğŸ”—Abrir en Google Colab**](https://colab.research.google.com/drive/1UT2_Practica7_FairlearnBiasDemo)
---

## Referencias

- Kaggle: *Ames Housing Dataset*.  
- Scikit-learn: *Preprocessing, Pipelines & Model Evaluation*.  
- Pandas & Seaborn Documentation.  
- Kurucz, J.F. (2025). *Feature Scaling & Anti-Leakage Pipeline â€“ UCU IngenierÃ­a de Datos*.

---

## NavegaciÃ³n

- [â¬…ï¸ Volver a UT2](../main.md)  
- [â¡ï¸ Ir a PrÃ¡ctica 7 â€” Feature Engineering](../practica7/main7.md)
