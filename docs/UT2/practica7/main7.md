---
title: Sesgo bajo la lupa ‚Äî Detecci√≥n, correcci√≥n y decisiones √©ticas con Fairlearn
date: 2025-09-24
---

## Contexto

Los modelos de aprendizaje autom√°tico aprenden patrones a partir de datos hist√≥ricos, y cuando esos datos reflejan desigualdades estructurales, el modelo puede amplificarlas.  
La detecci√≥n y correcci√≥n de sesgos se vuelve entonces una tarea esencial para garantizar el uso responsable de la inteligencia artificial.

En esta pr√°ctica se trabaj√≥ con dos casos de estudio complementarios:  

1. **Boston Housing (Regresi√≥n):** dataset eliminado de scikit-learn por contener una variable racial problem√°tica que codifica la proporci√≥n de poblaci√≥n afroamericana.  
2. **Titanic (Clasificaci√≥n):** dataset donde las diferencias de supervivencia reproducen sesgos sociales basados en g√©nero y clase social.

El objetivo fue aplicar m√©todos de fairness mediante la librer√≠a **Fairlearn**, para detectar, medir y mitigar sesgos, evaluando tanto el impacto t√©cnico como las implicancias √©ticas.

---

## Objetivos

- Detectar la presencia de sesgos en modelos predictivos basados en datos reales.  
- Analizar c√≥mo las variables sensibles afectan la equidad del modelo.  
- Implementar estrategias de correcci√≥n de sesgo y evaluar su impacto en rendimiento.  
- Comprender el equilibrio entre precisi√≥n, equidad y responsabilidad profesional.  
- Reflexionar sobre las decisiones √©ticas involucradas en el desarrollo de modelos.

---

## Desarrollo

1. **Carga y exploraci√≥n de datasets.**  
   Se cargaron los conjuntos de datos *Boston Housing* y *Titanic*.  
   En el caso de Boston, se reconstruy√≥ la variable racial `Bk_racial` a partir de la f√≥rmula original eliminada de la versi√≥n actual de scikit-learn.  
   En Titanic, se prepararon las variables num√©ricas y se eliminaron valores faltantes en edad y puerto de embarque.

2. **An√°lisis del sesgo.**  
   En Boston se calcul√≥ la correlaci√≥n entre la variable racial y el precio medio de las viviendas (`MEDV`).  
   En Titanic se calcularon las tasas de supervivencia por g√©nero y clase, confirmando una diferencia significativa a favor de las mujeres y los pasajeros de primera clase.

3. **Entrenamiento de modelos base.**  
   - Para Boston, se utiliz√≥ **regresi√≥n lineal** incluyendo y excluyendo la variable racial.  
   - Para Titanic, se aplic√≥ un **Random Forest** sin restricciones de equidad como modelo baseline.  

4. **Aplicaci√≥n de Fairlearn.**  
   En el caso Titanic, se utiliz√≥ el m√©todo **ExponentiatedGradient** con la restricci√≥n de *Demographic Parity*.  
   Se entren√≥ un modelo ajustado que busc√≥ equilibrar las tasas de predicci√≥n positiva entre hombres y mujeres.

5. **Evaluaci√≥n y comparaci√≥n.**  
   Se compararon los resultados de precisi√≥n y de equidad antes y despu√©s de aplicar la correcci√≥n, cuantificando la p√©rdida de rendimiento y la ganancia en justicia algor√≠tmica.

---

## Evidencias


### Disparidad entre g√©neros ‚Äì Antes vs Despu√©s de Fairlearn
![Disparidad entre g√©neros ‚Äì Antes vs Despu√©s de Fairlearn](Fairlearn.png)

**Observaci√≥n t√©cnica:**  
El gr√°fico muestra una reducci√≥n clara en la diferencia de paridad demogr√°fica tras aplicar Fairlearn.  
El modelo baseline presenta una disparidad cercana a 0.11, mientras que el modelo ajustado con mitigaci√≥n cae a aproximadamente 0.06.

**Interpretaci√≥n anal√≠tica:**  
La intervenci√≥n reduce la brecha de predicci√≥n entre g√©neros, disminuyendo el sesgo en la tasa de supervivencia predicha para hombres y mujeres.  

**Reflexi√≥n metodol√≥gica:**  
La mitigaci√≥n de sesgos con Fairlearn logra una mejora significativa en equidad sin modificar el dataset original, demostrando que la correcci√≥n algor√≠tmica puede ser efectiva incluso en etapas posteriores del pipeline.

---

### Tasa predicha de supervivencia por g√©nero
![Tasa predicha de supervivencia por g√©nero](Tasa_predicha.png)

**Observaci√≥n t√©cnica:**  
El modelo baseline predice una mayor tasa de supervivencia para mujeres (‚âà0.45) que para hombres (‚âà0.35).  
Tras aplicar Fairlearn, las tasas convergen hacia valores similares (‚âà0.27 para ambos).  

**Interpretaci√≥n anal√≠tica:**  
El ajuste del modelo reduce la diferencia entre g√©neros sin eliminar por completo la variabilidad natural de los datos.  
Esto sugiere que la mitigaci√≥n logra balancear las probabilidades sin sacrificar el comportamiento estructural del dataset.  

**Reflexi√≥n metodol√≥gica:**  
Fairlearn no busca igualar forzosamente los resultados, sino disminuir las diferencias no justificadas por factores explicativos v√°lidos.

---

### Trade-off entre rendimiento y equidad
![Trade-off entre rendimiento y equidad](Rendimiento_equidad.png)

**Observaci√≥n t√©cnica:**  
Se observa un descenso moderado del accuracy tras aplicar Fairlearn (de ~68% a ~64%), mientras que la disparidad demogr√°fica se reduce casi a la mitad.  

**Interpretaci√≥n anal√≠tica:**  
Este comportamiento confirma el cl√°sico compromiso entre precisi√≥n y justicia: mejorar la equidad puede implicar una leve p√©rdida de rendimiento global.  

**Reflexi√≥n metodol√≥gica:**  
El objetivo no es maximizar una m√©trica aislada, sino lograr un balance √©tico entre desempe√±o predictivo y tratamiento justo hacia los distintos grupos.

---

### Distribuci√≥n de precios por grupo racial
![Distribuci√≥n de precios por grupo racial](Boxplot.png)

**Observaci√≥n t√©cnica:**  
Las viviendas en √°reas con alta proporci√≥n de poblaci√≥n afroamericana presentan precios promedio m√°s bajos y mayor dispersi√≥n.  
El boxplot y los histogramas refuerzan esta diferencia estructural.  

**Interpretaci√≥n anal√≠tica:**  
La disparidad no necesariamente implica discriminaci√≥n directa, pero revela desigualdad subyacente en los datos, que puede trasladarse a los modelos si no se controla.  

**Reflexi√≥n metodol√≥gica:**  
El an√°lisis previo a la modelizaci√≥n permite identificar posibles fuentes de sesgo estructural.  
Mitigar o compensar estas diferencias debe ser parte del dise√±o √©tico de cualquier pipeline de aprendizaje autom√°tico.

---

## Insights clave

1. Los modelos precisos pueden ser injustos si no se analizan m√©tricas de equidad.  
2. Las variables sensibles no deben eliminarse sin antes medir su efecto en el sesgo.  
3. El contexto define la tolerancia √©tica al sesgo: en √°mbitos sociales, la equidad es prioritaria.  
4. Fairlearn permite cuantificar y mitigar desigualdades de manera controlada y reproducible.  
5. Rendimiento y equidad no son opuestos: con un dise√±o √©tico, pueden coexistir.

---

## Reflexi√≥n

El caso **Boston Housing** muestra c√≥mo el uso de variables sensibles puede introducir discriminaciones hist√≥ricas en un modelo.  
Aunque la variable `B` mejora el ajuste, representa informaci√≥n que perpet√∫a desigualdades.  
Excluirla de los modelos de producci√≥n es una decisi√≥n √©tica necesaria, aun cuando implique una leve p√©rdida de rendimiento.

El caso **Titanic** evidencia c√≥mo los sesgos de contexto (g√©nero, clase) pueden afectar la imparcialidad de los resultados.  
La correcci√≥n mediante *Fairlearn* demostr√≥ que es posible alcanzar un modelo m√°s equilibrado, validando la importancia de incluir m√©tricas de equidad en el proceso de modelado.

Ambos ejercicios llevan a una conclusi√≥n central: **no existe neutralidad algor√≠tmica**.  
Los modelos reproducen los valores y estructuras de quienes los construyen.  
Por ello, la √©tica no es un complemento del proceso t√©cnico, sino un requisito esencial para garantizar la validez y la justicia de los sistemas basados en datos.

---

## Notebook en Google Colab

üìì El notebook completo con el desarrollo de esta pr√°ctica puede consultarse en el siguiente enlace:

üîó [Abrir en Google Colab](https://colab.research.google.com/github/Agustina-Esquibel/Ingenieria-datos/blob/main/docs/UT2/practica7/UT2_practica7.ipynb)


---

## Referencias

- Fairlearn Documentation (Microsoft Research).  
- Scikit-learn: *Model Evaluation and Ethics in Machine Learning*.  
- CMU Boston Housing Dataset (1978).  
- Titanic Dataset (Kaggle / Seaborn).  

---

## Navegaci√≥n

[‚¨ÖÔ∏è Volver a Pr√°ctica 6 ‚Äî Feature Scaling y Anti-Leakage Pipeline](../practica6/main6.md)  
[‚¨ÖÔ∏è Volver a UT2](../main.md)  
[üìì √çndice del Portafolio](../../portfolio/index.md)
