---
title: "Portafolio - √çndice"
date: 2025-09-06
---

Pr√°cticas del curso de Ingenier√≠a de Datos, organizadas por unidades.  
Cada pr√°ctica contiene **objetivos, hallazgos principales y reflexiones**.

---

## Unidad Tem√°tica 1 ‚Äì An√°lisis Exploratorio y Fuentes

### üå∏ Explorando el Iris Dataset: primeros patrones florales y variables predictivas
Link: [Ver pr√°ctica](../UT1/practica1/main1.md)

**Objetivo:** 
Explorar el dataset Iris y aplicar un an√°lisis exploratorio inicial.  

**Hallazgos clave:**
- La especie *Setosa* se separa claramente de las dem√°s.
- Correlaciones fuertes entre el largo y el ancho de los p√©talos.
- Dataset balanceado con 50 registros por especie.

**Reflexi√≥n:** 
Esta pr√°ctica me ayud√≥ a familiarizarme con t√©cnicas b√°sicas de EDA y a ganar confianza en la interpretaci√≥n de correlaciones simples mediante visualizaciones claras.

---

### ‚öôÔ∏è Configuraci√≥n del portfolio en GitHub
Link: [Ver pr√°ctica](../UT1/practica2/main2.md)

**Objetivo:** 
Crear un repositorio en GitHub a partir del template y publicar el portafolio con GitHub Pages.  

**Hallazgos clave:**
- Repositorio configurado correctamente con estructura inicial de carpetas.
- GitHub Actions despleg√≥ el sitio sin errores.
- Portafolio visible online desde etapas tempranas.

**Reflexi√≥n:** 
Aunque no implic√≥ an√°lisis de datos, esta pr√°ctica fue esencial para organizar el flujo de trabajo, mantener trazabilidad y asegurar que los resultados pudieran documentarse y compartirse f√°cilmente.

---

### üé¨ Explorando el cat√°logo de Netflix: tendencias globales y patrones de contenido audiovisual
Link: [Ver pr√°ctica](../UT1/practica3/main3.md)

**Objetivo:** 
Analizar el cat√°logo de Netflix considerando a√±os, tipos de contenido, pa√≠ses y duraci√≥n.  

**Hallazgos clave:**
- Predominio de pel√≠culas sobre series.
- Crecimiento sostenido de estrenos desde 2016.
- Concentraci√≥n de la producci√≥n en pocos pa√≠ses (principalmente EE.UU. e India).

**Reflexi√≥n:** 
Trabajar con este dataset me permiti√≥ enfrentarme a problemas reales de datos incompletos y extraer conclusiones a partir de visualizaciones que evidencian patrones de la industria audiovisual.

---

### üöï Analizando los viajes de Nueva York: integraci√≥n de m√∫ltiples fuentes y comparaci√≥n con Joins

Link: [Ver pr√°ctica](../UT1/practica4/main4.md)

**Objetivo:** 
Integrar datasets de viajes, zonas y calendario para aplicar distintos *joins* y enriquecer el an√°lisis.  

**Hallazgos clave:**
- El `LEFT JOIN` permiti√≥ preservar todos los viajes, incluso sin coincidencia en zonas.
- Se observaron diferencias en la cantidad de viajes entre d√≠as normales y especiales.
- Boroughs con mayores vol√∫menes de viajes: Manhattan, Queens y Brooklyn.

**Reflexi√≥n:** 
Esta pr√°ctica fue la m√°s desafiante de la UT1, porque implic√≥ integraci√≥n de m√∫ltiples fuentes y an√°lisis temporal. Me permiti√≥ valorar c√≥mo la correcta uni√≥n de datasets cambia el nivel de los insights obtenidos.

---

üõçÔ∏è **Explorando el cat√°logo de moda: an√°lisis de precios y marcas**  
Link: [Ver pr√°ctica](../UT1/extraUT1/extramain.md)

**Objetivo:**  
Analizar datos de ventas de moda en formato JSON para comparar precios, marcas y temporadas, aplicando t√©cnicas de EDA y visualizaci√≥n.

**Hallazgos clave:**  
- Se identificaron diferencias de precios promedio entre categor√≠as y marcas.  
- Las marcas *Zara*, *Mango* y *Banana Republic* destacaron por tener mayor volumen en cat√°logo.  
- Los precios mostraron variaciones estacionales con picos en primavera y oto√±o.  

**Reflexi√≥n:**  
Este an√°lisis permiti√≥ trasladar lo aprendido en la UT1 a un nuevo dominio y formato de datos (JSON), fortaleciendo la capacidad para limpiar, explorar y visualizar informaci√≥n estructurada en contextos comerciales.

---

## Unidad Tem√°tica 2 ‚Äî Limpieza, imputaci√≥n y √©tica de datos

### üß± Ames Housing bajo la lupa: reconstrucci√≥n de informaci√≥n faltante  
*Link:* [Ver pr√°ctica](../UT2/practica5/main5.md)  

**Objetivo:** Detectar y analizar valores faltantes en el dataset Ames Housing, aplicando estrategias de imputaci√≥n contextual y reproducible.  

**Hallazgos clave:**  
- Los mecanismos de *missing data* var√≠an seg√∫n la variable (MCAR, MAR, MNAR).  
- La imputaci√≥n contextual mejora la consistencia sin distorsionar distribuciones clave.  
- Documentar el proceso aumenta la trazabilidad y transparencia metodol√≥gica.  
**Reflexi√≥n:** Aprend√≠ a aplicar imputaciones robustas y justificar decisiones t√©cnicas desde una mirada √©tica y reproducible.

---

### ‚öôÔ∏è Escalado y Anti-Leakage Pipeline: preprocesamiento √©tico y reproducible  
*Link:* [Ver pr√°ctica](../UT2/practica6/main6.md)  

**Objetivo:** Implementar un pipeline que normalice, escale y transforme datos sin fuga de informaci√≥n entre *train* y *test*.  

**Hallazgos clave:**  
- El *feature scaling* puede alterar relaciones estad√≠sticas si no se controla el *data leakage*.  
- Los m√©todos `StandardScaler`, `MinMaxScaler` y `RobustScaler` muestran comportamientos distintos ante outliers.  
- El *log transform* mejora la simetr√≠a de variables muy sesgadas.  
**Reflexi√≥n:** Fortalec√≠ el criterio para dise√±ar procesos de preprocesamiento reproducibles y √©ticamente responsables.

---

### ‚öñÔ∏è Sesgo bajo la lupa: detecci√≥n, correcci√≥n y decisiones √©ticas con Fairlearn  
*Link:* [Ver pr√°ctica](../UT2/practica7/main7.md)  

**Objetivo:** Detectar, medir y mitigar sesgos en modelos predictivos mediante m√©tricas de *fairness* aplicadas a casos reales (Boston Housing y Titanic).  

**Hallazgos clave:**  
- Los sesgos hist√≥ricos influyen directamente en los modelos si no se corrigen.  
- Fairlearn permite equilibrar *accuracy* y equidad de manera cuantificable.  
- Las decisiones √©ticas requieren evaluar impacto social, no solo rendimiento.  
**Reflexi√≥n:** Comprend√≠ c√≥mo la equidad y la √©tica son parte del ciclo t√©cnico de un modelo, no un a√±adido posterior.

## Unidad Tem√°tica 3 ‚Äì Feature Engineering

### üè° Dise√±ando el valor oculto: c√≥mo el feature engineering mejora la predicci√≥n de precios de vivienda  
Link: [Ver pr√°ctica](../UT3/practica8/main8.md)

**Objetivo:**  
Aplicar t√©cnicas de *feature engineering* num√©rico y de interacci√≥n para mejorar la capacidad predictiva en un problema de precios de vivienda.

**Hallazgos clave:**  
- Transformaciones como `log_price` y `price_per_sqft` aportaron estabilidad y mayor se√±al predictiva.
- Las features derivadas (eficiencia del espacio, densidad interna, interacci√≥n precio‚Äìantig√ºedad) capturaron relaciones no lineales relevantes.
- El an√°lisis valid√≥ la importancia de combinar transformaciones matem√°ticas con conocimiento del dominio inmobiliario.

**Reflexi√≥n:**  
Esta pr√°ctica permiti√≥ comprender c√≥mo el dise√±o de variables puede potenciar significativamente el rendimiento del modelo, incluso m√°s que cambios en el algoritmo. El *feature engineering* se consolid√≥ como una herramienta estrat√©gica cuando se aplica con criterio t√©cnico y de negocio.

---

### üß© Codificando la realidad: c√≥mo el encoding categ√≥rico mejora la predicci√≥n de ingresos en datos del censo  
Link: [Ver pr√°ctica](../UT3/practica9/main9.md)

**Objetivo:**  
Evaluar y comparar distintos m√©todos de codificaci√≥n categ√≥rica en un dataset con alta cardinalidad.

**Hallazgos clave:**  
- El *target encoding* obtuvo el mejor desempe√±o ante categor√≠as numerosas.
- One-Hot Encoding gener√≥ expansi√≥n dimensional significativa.
- Label Encoding fue √∫til en variables con componente ordinal, pero introdujo orden artificial en categor√≠as nominales.

**Reflexi√≥n:**  
La pr√°ctica resalt√≥ que la correcta selecci√≥n del m√©todo de codificaci√≥n tiene un impacto directo en la calidad del modelo. Adaptar el encoding al tipo de variable result√≥ clave para mantener interpretabilidad y eficiencia.

---

### üéõÔ∏è Reduciendo el ruido: c√≥mo PCA y Feature Selection revelan las variables clave del valor inmobiliario  
Link: [Ver pr√°ctica](../UT3/practica10/main10.md)

**Objetivo:**  
Aplicar PCA y t√©cnicas de selecci√≥n de variables para identificar las *features* m√°s importantes en un modelo de predicci√≥n de precios.

**Hallazgos clave:**  
- PCA conserv√≥ +90% de la varianza con pocas componentes.
- Mutual Information y SelectKBest permitieron aislar un conjunto estable de variables relevantes.
- La combinaci√≥n de reducci√≥n dimensional y selecci√≥n mejor√≥ la interpretabilidad y redujo sobreajuste.

**Reflexi√≥n:**  
Esta pr√°ctica reforz√≥ la importancia de eliminar redundancia y ruido en datasets complejos. La reducci√≥n dimensional demostr√≥ ser fundamental para simplificar el modelo sin perder capacidad predictiva.

---

### ‚è≥ Modelando el tiempo: c√≥mo el feature engineering temporal anticipa la recompra en e-commerce  
Link: [Ver pr√°ctica](../UT3/practica11/main11.md)

**Objetivo:**  
Dise√±ar un pipeline temporal para predecir *repeat purchase* mediante lag features, rolling windows, RFM analysis y validaci√≥n temporal estricta.

**Hallazgos clave:**  
- Las lag features y ventanas m√≥viles capturaron patrones hist√≥ricos esenciales.
- RFM (Recency‚ÄìFrequency‚ÄìMonetary) aport√≥ informaci√≥n robusta sobre comportamiento del cliente.
- TimeSeriesSplit evit√≥ *data leakage* y permiti√≥ evaluar el modelo en un contexto temporal realista.

**Reflexi√≥n:**  
La pr√°ctica evidenci√≥ que en modelos temporales, el manejo del tiempo y la prevenci√≥n de *leakage* son tan importantes como las propias features. El enfoque temporal demostr√≥ mejorar la performance considerablemente frente a un modelo base sin ingenier√≠a temporal.

---

## Unidad Tem√°tica 4 ‚Äì Datos Especiales

### üó∫Ô∏è Geointeligencia urbana: cobertura del SUBTE, densidad poblacional y demanda vecinal en Buenos Aires  
Link: [Ver pr√°ctica](../UT4/practica12/main12.md)

**Objetivo:**  
Analizar datos geoespaciales reales aplicando GeoPandas y Shapely para integrar capas urbanas (subte, barrios, densidad poblacional) y detectar zonas prioritarias seg√∫n accesibilidad y demanda.

**Hallazgos clave:**  
- Identificaci√≥n de barrios con menor cobertura del transporte p√∫blico.  
- Cruce exitoso de capas geogr√°ficas mediante *overlay* y *spatial join*.  
- Variaciones en densidad poblacional permiten detectar zonas con desbalance entre oferta y demanda.

**Reflexi√≥n:**  
Esta pr√°ctica permiti√≥ entender c√≥mo los datos geoespaciales ampl√≠an el an√°lisis m√°s all√° de las tablas tradicionales, incorporando contexto territorial y espacial para generar insights urbanos significativos.

---

### üì∏ Visi√≥n computacional aplicada: diagn√≥stico, contraste y extracci√≥n de descriptores con OpenCV  
Link: [Ver pr√°ctica](../UT4/practica13/main13.md)

**Objetivo:**  
Implementar un pipeline de preprocesamiento de im√°genes, incluyendo conversi√≥n de espacios de color, histogramas, mejora de contraste global/local y extracci√≥n de features (SIFT/ORB).

**Hallazgos clave:**  
- Comparaci√≥n clara entre im√°genes en RGB vs. escala de grises.  
- El contraste adaptativo (CLAHE) mejora zonas oscuras sin saturar el resto de la imagen.  
- Los descriptores SIFT/ORB generan puntos clave robustos para tareas posteriores de ML o matching.

**Reflexi√≥n:**  
Esta pr√°ctica mostr√≥ c√≥mo la preparaci√≥n de im√°genes impacta directamente en la calidad de los features. Introdujo las bases del procesamiento visual y la importancia de preparar correctamente los datos antes de cualquier modelo.

---

### üéß Audio para Machine Learning: limpieza, visualizaci√≥n y extracci√≥n de MFCC  
Link: [Ver pr√°ctica](../UT4/practica14/main14.md)

**Objetivo:**  
Dise√±ar un pipeline de preprocesamiento de audio: carga, inspecci√≥n visual, limpieza b√°sica, transformaci√≥n a espectrogramas y extracci√≥n de MFCC listos para su uso en modelos de ML.

**Hallazgos clave:**  
- La visualizaci√≥n de la forma de onda y el espectrograma permite detectar ruido, silencios y patrones temporales.  
- Los MFCC capturan caracter√≠sticas esenciales del timbre y permiten representar audio en formato num√©rico comparable.  
- La estandarizaci√≥n del pipeline garantiza que todos los audios produzcan features consistentes.

**Reflexi√≥n:**  
Trabajar con audio mostr√≥ la importancia de adaptar el pipeline a cada tipo de dato. La pr√°ctica fortaleci√≥ la comprensi√≥n de c√≥mo transformar se√±ales crudas en informaci√≥n estructurada para modelos de aprendizaje.

---

## Unidad Tem√°tica 5 ‚Äì Pipelines ETL

### ‚òÅÔ∏è Datos en movimiento: creando un pipeline ETL en Google Cloud  
Link: [Ver pr√°ctica](../UT5/practica15/main15.md)

**Objetivo:**  
Implementar un pipeline ETL/ELT utilizando Cloud Storage, Cloud Functions y BigQuery, con ejecuci√≥n basada en eventos y transformaci√≥n posterior.

**Hallazgos clave:**  
- Activaci√≥n autom√°tica del pipeline mediante triggers.  
- Flujo ELT: carga inicial en BigQuery y transformaciones posteriores.  
- Integraci√≥n fluida entre almacenamiento, funciones serverless y motor anal√≠tico.

**Reflexi√≥n:**  
Esta pr√°ctica permiti√≥ ver c√≥mo funciona un pipeline moderno en la nube: automatizado, reproducible y sin tareas manuales.

---

### üßΩ DataPrep: limpieza visual de datos orientada a pipeline  
Link: [Ver pr√°ctica](../UT5/practica16/main16.md)

**Objetivo:**  
Crear un pipeline ETL visual con Dataprep, aplicando reglas reproducibles de limpieza y transformaci√≥n integradas con BigQuery.

**Hallazgos clave:**  
- Perfilado autom√°tico de calidad de datos.  
- Transformaciones visuales versionadas como reglas.  
- Exportaci√≥n directa a sistemas anal√≠ticos.

**Reflexi√≥n:**  
Dataprep mostr√≥ c√≥mo dise√±ar pipelines ETL sin c√≥digo, manteniendo trazabilidad, documentaci√≥n y consistencia entre ejecuciones.

---
  
