---
title: "DataPrep: limpieza visual de datos orientada a pipeline"
date: 2025-12-07
---

## Contexto
Esta pr√°ctica corresponde al lab *"Cleaning Data with Dataprep"* de Google Cloud Skills.  
El objetivo principal es introducir al estudiante al uso de **Cloud Dataprep (Trifacta)**, una herramienta visual dise√±ada para **perfilar, limpiar, transformar y preparar datos** sin necesidad de escribir c√≥digo, generando flujos reproducibles ideales para pipelines ETL/ELT.

Dataprep combina automatizaci√≥n inteligente, recomendaciones guiadas y ejecuci√≥n escalable sobre Google Cloud, convirti√©ndose en una herramienta clave dentro de procesos modernos de **DataOps**.

---

## Objetivos
- Comprender c√≥mo funciona la **interfaz visual de Dataprep** para explorar, perfilar y transformar datos.  
- Aplicar operaciones esenciales de limpieza: detecci√≥n de valores faltantes, divisi√≥n de columnas, extracci√≥n de patrones, normalizaci√≥n y combinaci√≥n.  
- Crear un **workflow reproducible**, donde cada paso se registra como parte de un pipeline.  
- Ejecutar el job final para producir datos limpios, export√°ndolos a Cloud Storage o BigQuery.  
- Conocer buenas pr√°cticas de preparaci√≥n de datos antes de integrarlos en pipelines automatizados.

---

## Desarrollo

### 1. Inicio del entorno y carga del dataset
El estudiante inici√≥ el laboratorio en Google Cloud Skills, accediendo a Cloud Dataprep desde la consola.  
Luego:

- Se import√≥ un archivo CSV desde Cloud Storage.  
- Dataprep gener√≥ autom√°ticamente un **perfil de datos** que incluye tipos, valores faltantes, distribuciones y patrones.

Esta exploraci√≥n inicial permiti√≥ identificar problemas comunes como formatos inconsistentes, columnas mal tipadas o datos incompletos.

---

### 2. Perfilado y evaluaci√≥n de la calidad del dato
Dataprep mostr√≥ visualmente:

- Distribuciones por columna  
- Valores at√≠picos  
- Errores de formato  
- Frecuencias de categor√≠as  
- Indicadores de completitud  

El estudiante identific√≥ qu√© variables requer√≠an limpieza y qu√© transformaciones mejorar√≠an la coherencia del dataset.

---

### 3. Transformaciones de limpieza
Se aplicaron m√∫ltiples transformaciones guiadas:

- **Split** de columnas por delimitadores.  
- **Regex** para extraer subcadenas.  
- **Replace** para corregir valores inv√°lidos o inconsistentes.  
- **Trim**, **lowercase/uppercase**, normalizaci√≥n de texto.  
- Correcci√≥n de tipos de datos: conversi√≥n a num√©rico, fecha o categor√≠a.  
- Eliminaci√≥n de filas con datos incompletos seg√∫n criterios del ejercicio.  

Cada paso se a√±adi√≥ como un **step** dentro del flujo reproducible, permitiendo mantener trazabilidad.

---

### 4. Creaci√≥n del pipeline visual
Dataprep estructur√≥ todas las transformaciones dentro de un **recipe**, un pipeline visual que se puede:

- Revisar  
- Reordenar  
- Documentar  
- Ejecutar m√∫ltiples veces sobre nuevos datos  

Este enfoque permite mantener un proceso de limpieza estandarizado, esencial para pipelines ETL/ELT m√°s grandes.

---

### 5. Ejecuci√≥n del job y exportaci√≥n de resultados
Finalmente se ejecut√≥ el **job** del recipe para producir los datos limpios.  
El estudiante configur√≥ el destino del resultado:

- Exportaci√≥n a **Cloud Storage**, o  
- Carga directa en **BigQuery** para posteriores an√°lisis o dashboards.

La ejecuci√≥n mostr√≥ estad√≠sticas del job, tiempo de procesamiento y validaci√≥n final de datos.

---

## Evidencias

| Evidencia | Descripci√≥n |
|----------|-------------|
| Dataset cargado en Dataprep | Importaci√≥n del CSV y perfilado autom√°tico del contenido. |
| Perfil visual del dato | Distribuciones, tipos y detecci√≥n de problemas de calidad. |
| Transformaciones aplicadas | Split, replace, limpieza de texto y correcciones de formato. |
| Pipeline visual (recipe) | Secuencia de pasos reproducibles dentro del flujo. |
| Resultado exportado | Job ejecutado con datos procesados listos para an√°lisis. |

---

## Insights clave
- Dataprep facilita la limpieza y preparaci√≥n de datos mediante una interfaz intuitiva y sin c√≥digo.  
- El perfilado autom√°tico acelera la detecci√≥n de problemas, permitiendo concentrarse en decisiones anal√≠ticas.  
- Cada transformaci√≥n queda documentada como un paso del pipeline, reforzando buenas pr√°cticas de **DataOps**.  
- El recipe facilita **reproducibilidad**, **escalabilidad** y **mantenibilidad** del proceso de limpieza.  
- Integrar Dataprep dentro de un flujo ETL/ELT en Google Cloud reduce tiempos de preparaci√≥n y mejora la calidad final del dato.

---

## Reflexi√≥n
Esta pr√°ctica reforz√≥ la importancia de contar con herramientas que automaticen y estandaricen la preparaci√≥n de datos.  
El enfoque visual de Dataprep demuestra que la ingenier√≠a de datos no siempre requiere c√≥digo para alcanzar resultados profesionales: lo fundamental es la comprensi√≥n del proceso, la calidad del dato y la capacidad de reproducir transformaciones.

Se pudo observar c√≥mo una herramienta orientada a **pipelines escalables** permite transformar datos ruidosos en informaci√≥n lista para an√°lisis o carga en BigQuery.  
En conjunto, esta pr√°ctica complementa la visi√≥n de UT5: **pipeline + limpieza reproducible = datos confiables listos para producci√≥n.**

---

## Referencias
- Google Cloud Skills ‚Äì *Cleaning Data with Dataprep*  
- Dataprep by Trifacta ‚Äì Documentaci√≥n oficial  
- Google Cloud ‚Äì DataOps & Data Engineering guidelines  

---

## Navegaci√≥n
‚¨ÖÔ∏è [Volver a Unidad Tem√°tica 5](../main.md) 
üìì [√çndice del Portafolio](../../portfolio/index.md)
