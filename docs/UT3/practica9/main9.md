---
title: "Codificando la realidad: c√≥mo el encoding categ√≥rico mejora la predicci√≥n de ingresos en datos del censo"
date: 2025-10-15
---

## Contexto  
Esta pr√°ctica aborda el proceso de **codificaci√≥n avanzada de variables categ√≥ricas** dentro del flujo de *machine learning*, utilizando el cl√°sico **Adult Income Dataset** del Censo de Estados Unidos (1994), con m√°s de 48.000 registros.  
El objetivo del caso es **predecir si una persona percibe ingresos superiores a 50.000 d√≥lares anuales**, a partir de variables demogr√°ficas y laborales que incluyen educaci√≥n, ocupaci√≥n, pa√≠s de origen y estado civil.  

El desaf√≠o central radica en la **alta cardinalidad** de ciertas variables categ√≥ricas (como `occupation` y `native-country`), que impiden el uso directo de t√©cnicas simples como *one-hot encoding* sin incrementar dr√°sticamente la dimensionalidad del conjunto de datos.  
Por ello, se implementan y comparan m√∫ltiples estrategias de codificaci√≥n ‚Äî*Label Encoding*, *One-Hot Encoding* y *Target Encoding*‚Äî evaluando su impacto en la **precisi√≥n, interpretabilidad y eficiencia del modelo de clasificaci√≥n**.  

La pr√°ctica se desarrolla bajo la metodolog√≠a **CRISP-DM**, con especial √©nfasis en la fase de *Data Preparation* y su influencia directa sobre los resultados del modelo predictivo.

---

## Objetivos  
- Analizar la **cardinalidad** de las variables categ√≥ricas y clasificarlas seg√∫n su complejidad.  
- Implementar y comparar m√∫ltiples t√©cnicas de **encoding** (Label, One-Hot, Target).  
- Prevenir **data leakage** mediante el uso de *cross-validation* en el *target encoding*.  
- Dise√±ar **pipelines escalables** utilizando `ColumnTransformer` y *branching*.  
- Evaluar el impacto de cada m√©todo sobre la **precisi√≥n, dimensionalidad y tiempo de entrenamiento**.  
- Documentar los resultados y reflexionar sobre los **trade-offs entre interpretabilidad y performance**.

---

## Actividades  

1. **Instalaci√≥n de dependencias y configuraci√≥n del entorno**  
   - Configuraci√≥n de Google Colab e instalaci√≥n de librer√≠as (`pandas`, `numpy`, `seaborn`, `category_encoders`, `scikit-learn`, `shap`).  

2. **Carga y exploraci√≥n del dataset real ‚Äì Adult Income (Census)**  
   - An√°lisis inicial del conjunto de datos y revisi√≥n de las variables categ√≥ricas.  
   - Identificaci√≥n de variables con **alta cardinalidad** (`occupation`: 15 valores, `native-country`: 42 valores).  

3. **Experimento 1 ‚Äì Label Encoding**  
   - Aplicaci√≥n del *LabelEncoder* sobre variables categ√≥ricas.  
   - Evaluaci√≥n del modelo de clasificaci√≥n (*Logistic Regression*) y registro de m√©tricas de precisi√≥n y recall.  
   - Observaci√≥n: p√©rdida de interpretabilidad y posible introducci√≥n de relaciones ordinales artificiales.  

4. **Experimento 2 ‚Äì One-Hot Encoding (baja cardinalidad)**  
   - Implementaci√≥n del *OneHotEncoder* sobre variables con menos de 10 categor√≠as.  
   - Reducci√≥n parcial de dimensionalidad mediante *ColumnTransformer*.  
   - Ventaja: alta interpretabilidad. Desventaja: incremento significativo en el n√∫mero de columnas.  

5. **Experimento 3 ‚Äì Target Encoding (alta cardinalidad)**  
   - Aplicaci√≥n de *TargetEncoder* de `category_encoders`, con validaci√≥n cruzada para evitar *data leakage*.  
   - C√°lculo de suavizado (*smoothing*) para mitigar el sobreajuste.  
   - Resultados: mejora en la precisi√≥n sin penalizar la eficiencia del modelo.  

6. **Pipeline con Branching ‚Äì ColumnTransformer**  
   - Construcci√≥n de un *pipeline h√≠brido* combinando las tres estrategias de encoding seg√∫n la cardinalidad.  
   - Uso de *branching* para aplicar t√©cnicas diferentes en paralelo dentro del mismo flujo de entrenamiento.  

7. **Explicabilidad ‚Äì Feature Importance y SHAP**  
   - Estimaci√≥n de la importancia de variables con `RandomForestClassifier`.  
   - Interpretaci√≥n de contribuciones locales mediante *SHAP values*, comprobando el peso relativo de variables transformadas.  

8. **Comparaci√≥n de resultados y trade-offs**  
   - Comparaci√≥n de m√©tricas entre m√©todos: precisi√≥n, F1-score y tiempo de entrenamiento.  
   - Discusi√≥n de los *trade-offs* entre complejidad, interpretabilidad y rendimiento.  

9. **Investigaci√≥n libre ‚Äì T√©cnicas adicionales**  
   - Implementaci√≥n de *Frequency Encoding* y *Ordinal Encoding* como variantes complementarias.  
   - An√°lisis del impacto marginal de estas t√©cnicas en modelos de √°rboles y regresi√≥n log√≠stica.  

---

## Desarrollo  

El desarrollo sigui√≥ un enfoque experimental progresivo basado en la comparaci√≥n emp√≠rica de m√©todos de codificaci√≥n.  
El trabajo comenz√≥ con la **exploraci√≥n de cardinalidad** y el an√°lisis de distribuci√≥n de categor√≠as, lo que permiti√≥ clasificar las variables seg√∫n su nivel de complejidad y definir una estrategia diferenciada para cada grupo.  

A partir de all√≠, se dise√±aron tres experimentos independientes (Label, One-Hot y Target Encoding) bajo un esquema controlado, utilizando las mismas m√©tricas, modelo base y divisi√≥n de datos para asegurar una comparaci√≥n justa.  
Cada pipeline fue implementado dentro de un `ColumnTransformer`, lo que permiti√≥ **modularizar las transformaciones** y mantener un flujo reproducible.  

En el caso del *Target Encoding*, se aplic√≥ validaci√≥n cruzada (*KFold*) para prevenir fugas de informaci√≥n entre conjuntos de entrenamiento y validaci√≥n.  
El par√°metro de *smoothing* se calibr√≥ para equilibrar la estabilidad de las medias y la variabilidad de las categor√≠as menos frecuentes.  

Finalmente, los resultados de cada t√©cnica fueron integrados y analizados con herramientas de interpretabilidad (*feature importance* y *SHAP*), lo que permiti√≥ cuantificar el efecto del encoding sobre la relevancia y comportamiento de las variables dentro del modelo.  
El pipeline resultante demostr√≥ la importancia de **elegir la t√©cnica adecuada seg√∫n la naturaleza de cada variable**, optimizando as√≠ la precisi√≥n sin comprometer la escalabilidad ni la claridad del modelo.

---

## Evidencias  
üïì *(Secci√≥n pendiente de completar con las visualizaciones y resultados una vez integrados al notebook.)*  
> **Sugerencia:** al subir los gr√°ficos, acompa√±alos con una breve interpretaci√≥n.  
> Ejemplo:  
> **Figura 1.** Comparaci√≥n de precisi√≥n entre m√©todos de encoding ‚Äî *Target Encoding* alcanza un 87% de accuracy, superando al *One-Hot* con menor costo computacional.  
> **Figura 2.** Gr√°fico de importancia de variables ‚Äî se observa el aumento de peso en las categor√≠as transformadas mediante *target encoding*.  

---

## Insights clave  

- El *feature encoding* es una etapa determinante para la **eficiencia y generalizaci√≥n** del modelo.  
- El *Label Encoding* resulta adecuado solo para algoritmos basados en √°rboles, donde la jerarqu√≠a num√©rica no induce sesgos.  
- El *One-Hot Encoding* mantiene interpretabilidad, pero **penaliza la dimensionalidad**, especialmente en variables con alta cardinalidad.  
- El *Target Encoding*, correctamente implementado con *cross-validation*, logra **mejor precisi√≥n y estabilidad**, evitando fugas de informaci√≥n.  
- Los *pipelines h√≠bridos* permiten integrar m√∫ltiples m√©todos seg√∫n la naturaleza de las variables, optimizando la relaci√≥n entre complejidad y desempe√±o.  
- Las m√©tricas obtenidas y el an√°lisis con *SHAP* demostraron que la codificaci√≥n influye directamente en la **importancia relativa de las variables** y en la transparencia del modelo.

---

## Reflexi√≥n  

Esta pr√°ctica permiti√≥ comprender el **rol cr√≠tico del encoding categ√≥rico** como puente entre los datos reales y la capacidad predictiva de los modelos.  
El proceso evidenci√≥ que la calidad de la representaci√≥n de las variables categ√≥ricas **determina en gran medida la precisi√≥n, la interpretabilidad y la eficiencia computacional** del modelo final.  

La comparaci√≥n de t√©cnicas mostr√≥ que no existe un m√©todo universalmente superior: cada enfoque presenta **trade-offs espec√≠ficos** entre complejidad, escalabilidad y robustez.  
El *Target Encoding* se destac√≥ por su balance entre poder predictivo y control de dimensionalidad, siempre que se aplique con mecanismos de validaci√≥n que eviten *data leakage*.  

Desde una perspectiva de ingenier√≠a de datos, la pr√°ctica reafirma que **las decisiones tomadas en la etapa de preparaci√≥n son tan importantes como la elecci√≥n del modelo en s√≠**, y que un pipeline bien dise√±ado puede marcar la diferencia entre un modelo funcional y uno verdaderamente confiable.  

En s√≠ntesis, el *feature encoding* se consolida como una fase estrat√©gica del proceso anal√≠tico: **transforma la informaci√≥n categ√≥rica del mundo real en representaciones matem√°ticas que los algoritmos pueden entender, sin perder su significado original.**

---

## Notebook en Google Colab  
üìì El notebook completo con el desarrollo de esta pr√°ctica puede consultarse en el siguiente enlace:  
*(agregar link real al notebook publicado en Colab o GitHub)*  

---

## üîó Referencias oficiales  
- [Category Encoders Library](https://contrib.scikit-learn.org/category_encoders/)  
- [Scikit-learn Preprocessing Documentation](https://scikit-learn.org/stable/modules/preprocessing.html)  
- [Feature Engineering for Machine Learning ‚Äì O‚ÄôReilly, Cap. 5](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)  
- [Kaggle Feature Engineering ‚Äì Target Encoding Guide](https://www.kaggle.com/code/ryanholbrook/target-encoding)  

---

## Navegaci√≥n  
‚¨ÖÔ∏è [Volver a Pr√°ctica 8](../practica8/main8.md)  
‚û°Ô∏è [Ir a Pr√°ctica 10](../practica10/main10.md)  
üìì [√çndice del Portafolio](../../portfolio/index.md)
