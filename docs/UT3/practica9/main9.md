---
title: "Codificando la realidad: c√≥mo el encoding categ√≥rico mejora la predicci√≥n de ingresos en datos del censo"
date: 2025-10-15
---

## Contexto  
Esta pr√°ctica explora el impacto del **encoding categ√≥rico** en modelos de clasificaci√≥n, utilizando el dataset **Adult Income (Census 1994)**.  
El objetivo es predecir si una persona supera los 50.000 USD anuales a partir de variables demogr√°ficas, laborales y socioecon√≥micas.

La presencia de variables categ√≥ricas con **alta cardinalidad** hace necesario comparar diferentes t√©cnicas de encoding ‚ÄîLabel, One-Hot y Target Encoding‚Äî evaluando su impacto en la precisi√≥n, dimensionalidad y estabilidad del modelo.  
El trabajo sigue una metodolog√≠a CRISP-DM, con √©nfasis en *Data Preparation* y la importancia √©tica del preprocesamiento correcto (evitando leakage).

---

## Objetivos  
- Analizar cardinalidad y complejidad de las variables categ√≥ricas.  
- Implementar y comparar m√∫ltiples t√©cnicas de codificaci√≥n.  
- Evitar *data leakage* mediante validaci√≥n cruzada en Target Encoding.  
- Dise√±ar un pipeline escalable con ColumnTransformer y branching.  
- Evaluar el impacto de cada m√©todo en m√©tricas y eficiencia.  
- Interpretar resultados mediante *feature importance* y *SHAP*.

---

## Actividades  

### 1. Exploraci√≥n inicial  
Se analiz√≥ la cardinalidad de las variables categ√≥ricas, clasific√°ndolas en:

- **Baja cardinalidad:** adecuadas para One-Hot.  
- **Alta cardinalidad:** requieren estrategias como Target Encoding.  

### 2. Experimento 1 ‚Äî Label Encoding  
Ventaja: r√°pido y compacto.  
Desventaja: introduce artificialmente orden y distancia entre categor√≠as.

### 3. Experimento 2 ‚Äî One-Hot Encoding  
Adecuado para baja cardinalidad.  
Incrementa dimensionalidad: se controla mediante ColumnTransformer.

### 4. Experimento 3 ‚Äî Target Encoding  
Justificaci√≥n t√©cnica: captura relaci√≥n directa entre la categor√≠a y la probabilidad del target.  
Justificaci√≥n √©tica: evita leakage utilizando validaci√≥n cruzada (KFold).  

### 5. Pipeline h√≠brido  
Se construy√≥ un pipeline con **branching**, asignando:

- Label Encoding ‚Üí modelos basados en √°rboles.  
- One-Hot ‚Üí baja cardinalidad.  
- Target Encoding ‚Üí alta cardinalidad.

### 6. Interpretabilidad  
Se aplicaron **feature importance** y **SHAP values** para analizar el peso de variables num√©ricas y categ√≥ricas codificadas.

---

## Desarrollo  

El trabajo sigui√≥ una estrategia comparativa controlada: mismo modelo base, mismas m√©tricas, mismo split.  
Cada encoding se prob√≥ de forma aislada para evaluar rendimiento, luego se integraron en un pipeline mixto optimizado.  
El Target Encoding se implement√≥ con suavizado (**smoothing**) y validaci√≥n cruzada, reduciendo varianza en categor√≠as poco frecuentes.

El an√°lisis se complement√≥ con explicabilidad a partir de SHAP, cuantificando c√≥mo cambia la contribuci√≥n de cada variable cuando se aplican distintos encodings.

---

## Evidencias  

### Cardinalidad de Variables Categ√≥ricas  
![Cardinalidad de Variables Categ√≥ricas](IMG_4254.png)  
**Conclusi√≥n:** La alta cardinalidad de variables como `native-country` y `occupation` justifica el uso de Target Encoding para evitar explosi√≥n dimensional.

### Distribuci√≥n de Education seg√∫n nivel de ingreso  
![Distribuci√≥n Education](IMG_4326.png)  
**Conclusi√≥n:** La proporci√≥n de ingresos altos crece con el nivel educativo, reforzando la relevancia de codificar correctamente la variable `education`.

### Distribuci√≥n de Occupation seg√∫n nivel de ingreso  
![Distribuci√≥n Occupation](IMG_4261.png)  
**Conclusi√≥n:** Profesiones t√©cnicas y administrativas muestran mayor proporci√≥n de ingresos superiores, indicando que un encoding m√°s expresivo captura mejor estas relaciones.

### Distribuci√≥n de Relationship seg√∫n nivel de ingreso  
![Distribuci√≥n Relationship](IMG_4262.png)  
**Conclusi√≥n:** La categor√≠a ‚ÄúHusband‚Äù muestra la mayor proporci√≥n de ingresos altos; este patr√≥n influye en el comportamiento del modelo si no se codifica correctamente.

### Matriz de Correlaciones ‚Äì Variables num√©ricas  
![Matriz de Correlaciones Num√©ricas](IMG_4258.png)  
**Conclusi√≥n:** `education-num`, `age` y `capital-gain` son las variables num√©ricas m√°s relacionadas con el target; sirven como baseline para comparar la contribuci√≥n del encoding.

### Matriz de Correlaciones (Top variables)  
![Matriz de Correlaciones Top](IMG_4328.png)  
**Conclusi√≥n:** El an√°lisis refinado identifica variables cr√≠ticas, √∫tiles para priorizar durante la selecci√≥n de features.

### Importancia de Features ‚Äì Modelo Final  
![Top 15 Features m√°s importantes](IMG_4257.png)  
**Conclusi√≥n:** Tras el pipeline mixto, las variables m√°s influyentes combinan num√©ricas y categ√≥ricas codificadas mediante Target Encoding.

### Importancia y Distribuci√≥n de Features  
![Distribuci√≥n Importancia de Features](IMG_4320.png)  
**Conclusi√≥n:** La dispersi√≥n evidencia qu√© variables aportan se√±al estable, validando la combinaci√≥n de m√©todos de encoding.

### Comparaci√≥n de Modelos y Codificaci√≥n  
![Comparaci√≥n de Modelos y Encoding](IMG_4252.png)  
**Conclusi√≥n operativa:**  
El pipeline mixto logra el mejor balance entre precisi√≥n, dimensionalidad y estabilidad, superando a cualquier m√©todo aplicado de forma aislada.

---

## Insights clave  

- El encoding categ√≥rico influye directamente en el rendimiento y la interpretabilidad.  
- No existe un m√©todo universal: depende de cardinalidad, distribuci√≥n y modelo utilizado.  
- Target Encoding ofrece la mejor relaci√≥n entre precisi√≥n y eficiencia cuando se controla el leakage.  
- Los pipelines h√≠bridos permiten aprovechar lo mejor de cada estrategia.  
- La explicabilidad revela c√≥mo el encoding modifica el peso relativo de las variables.

---

## Reflexi√≥n  

El proceso confirma que la representaci√≥n matem√°tica de las variables categ√≥ricas determina, en gran medida, el √©xito del modelo predictivo.  
Las decisiones tomadas en esta etapa tienen consecuencias √©ticas, t√©cnicas y operativas: afectan precision, interpretabilidad y el riesgo de sesgos ocultos.

El encoding categ√≥rico se consolida as√≠ como una fase estrat√©gica donde convergen estad√≠stica, dise√±o de pipelines y comprensi√≥n del dominio.  
Un m√©todo adecuado permite transformar datos heterog√©neos del mundo real en informaci√≥n estructurada, sin perder significado.

---

## Notebook en Google Colab  
üìì El notebook completo con el desarrollo de esta pr√°ctica puede consultarse en el siguiente enlace:  
[Abrir en Google Colab](https://colab.research.google.com/github/Agustina-Esquibel/Ingenieria-datos/blob/main/docs/UT3/practica9/UT3_Practica9.ipynb)

---

## Referencias  
- Category Encoders Library  
- Scikit-learn Preprocessing Documentation  
- Feature Engineering for Machine Learning ‚Äì O‚ÄôReilly  
- Kaggle Target Encoding Guide  

---

## Navegaci√≥n  
‚¨ÖÔ∏è Dise√±ando el valor oculto: Feature Engineering  
‚û°Ô∏è Reduciendo el ruido: PCA y Feature Selection  
üìì √çndice del Portafolio
