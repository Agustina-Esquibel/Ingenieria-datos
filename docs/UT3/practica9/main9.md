---
title: "Codificando la realidad: cÃ³mo el encoding categÃ³rico mejora la predicciÃ³n de ingresos en datos del censo"
date: 2025-10-15
---

## Contexto Â 
Esta prÃ¡ctica aborda el proceso de **codificaciÃ³n avanzada de variables categÃ³ricas** dentro del flujo de *machine learning*, utilizando el clÃ¡sico **Adult Income Dataset** del Censo de Estados Unidos (1994), con mÃ¡s de 48.000 registros. Â 
El objetivo del caso es **predecir si una persona percibe ingresos superiores a 50.000 dÃ³lares anuales**, a partir de variables demogrÃ¡ficas y laborales que incluyen educaciÃ³n, ocupaciÃ³n, paÃ­s de origen y estado civil. Â 

El desafÃ­o central radica en la **alta cardinalidad** de ciertas variables categÃ³ricas (como `occupation` y `native-country`), que impiden el uso directo de tÃ©cnicas simples como *one-hot encoding* sin incrementar drÃ¡sticamente la dimensionalidad del conjunto de datos. Â 
Por ello, se implementan y comparan mÃºltiples estrategias de codificaciÃ³n â€”*Label Encoding*, *One-Hot Encoding* y *Target Encoding*â€” evaluando su impacto en la **precisiÃ³n, interpretabilidad y eficiencia del modelo de clasificaciÃ³n**. Â 

La prÃ¡ctica se desarrolla bajo la metodologÃ­a **CRISP-DM**, con especial Ã©nfasis en la fase de *Data Preparation* y su influencia directa sobre los resultados del modelo predictivo.

---

## Objetivos Â 
- Analizar la **cardinalidad** de las variables categÃ³ricas y clasificarlas segÃºn su complejidad. Â 
- Implementar y comparar mÃºltiples tÃ©cnicas de **encoding** (Label, One-Hot, Target). Â 
- Prevenir **data leakage** mediante el uso de *cross-validation* en el *target encoding*. Â 
- DiseÃ±ar **pipelines escalables** utilizando `ColumnTransformer` y *branching*. Â 
- Evaluar el impacto de cada mÃ©todo sobre la **precisiÃ³n, dimensionalidad y tiempo de entrenamiento**. Â 
- Documentar los resultados y reflexionar sobre los **trade-offs entre interpretabilidad y performance**.

---

## Actividades Â 

1. **InstalaciÃ³n de dependencias y configuraciÃ³n del entorno** Â 
Â  Â - ConfiguraciÃ³n de Google Colab e instalaciÃ³n de librerÃ­as (`pandas`, `numpy`, `seaborn`, `category_encoders`, `scikit-learn`, `shap`). Â 

2. **Carga y exploraciÃ³n del dataset real â€“ Adult Income (Census)** Â 
Â  Â - AnÃ¡lisis inicial del conjunto de datos y revisiÃ³n de las variables categÃ³ricas. Â 
Â  Â - IdentificaciÃ³n de variables con **alta cardinalidad** (`occupation`: 15 valores, `native-country`: 42 valores). Â 

3. **Experimento 1 â€“ Label Encoding** Â 
Â  Â - AplicaciÃ³n del *LabelEncoder* sobre variables categÃ³ricas. Â 
Â  Â - EvaluaciÃ³n del modelo de clasificaciÃ³n (*Logistic Regression*) y registro de mÃ©tricas de precisiÃ³n y recall. Â 
Â  Â - ObservaciÃ³n: pÃ©rdida de interpretabilidad y posible introducciÃ³n de relaciones ordinales artificiales. Â 

4. **Experimento 2 â€“ One-Hot Encoding (baja cardinalidad)** Â 
Â  Â - ImplementaciÃ³n del *OneHotEncoder* sobre variables con menos de 10 categorÃ­as. Â 
Â  Â - ReducciÃ³n parcial de dimensionalidad mediante *ColumnTransformer*. Â 
Â  Â - Ventaja: alta interpretabilidad. Desventaja: incremento significativo en el nÃºmero de columnas. Â 

5. **Experimento 3 â€“ Target Encoding (alta cardinalidad)** Â 
Â  Â - AplicaciÃ³n de *TargetEncoder* de `category_encoders`, con validaciÃ³n cruzada para evitar *data leakage*. Â 
Â  Â - CÃ¡lculo de suavizado (*smoothing*) para mitigar el sobreajuste. Â 
Â  Â - Resultados: mejora en la precisiÃ³n sin penalizar la eficiencia del modelo. Â 

6. **Pipeline con Branching â€“ ColumnTransformer** Â 
Â  Â - ConstrucciÃ³n de un *pipeline hÃ­brido* combinando las tres estrategias de encoding segÃºn la cardinalidad. Â 
Â  Â - Uso de *branching* para aplicar tÃ©cnicas diferentes en paralelo dentro del mismo flujo de entrenamiento. Â 

7. **Explicabilidad â€“ Feature Importance y SHAP** Â 
Â  Â - EstimaciÃ³n de la importancia de variables con `RandomForestClassifier`. Â 
Â  Â - InterpretaciÃ³n de contribuciones locales mediante *SHAP values*, comprobando el peso relativo de variables transformadas. Â 

8. **ComparaciÃ³n de resultados y trade-offs** Â 
Â  Â - ComparaciÃ³n de mÃ©tricas entre mÃ©todos: precisiÃ³n, F1-score y tiempo de entrenamiento. Â 
Â  Â - DiscusiÃ³n de los *trade-offs* entre complejidad, interpretabilidad y rendimiento. Â 

9. **InvestigaciÃ³n libre â€“ TÃ©cnicas adicionales** Â 
Â  Â - ImplementaciÃ³n de *Frequency Encoding* y *Ordinal Encoding* como variantes complementarias. Â 
Â  Â - AnÃ¡lisis del impacto marginal de estas tÃ©cnicas en modelos de Ã¡rboles y regresiÃ³n logÃ­stica. Â 

---

## Desarrollo Â 

El desarrollo siguiÃ³ un enfoque experimental progresivo basado en la comparaciÃ³n empÃ­rica de mÃ©todos de codificaciÃ³n. Â 
El trabajo comenzÃ³ con la **exploraciÃ³n de cardinalidad** y el anÃ¡lisis de distribuciÃ³n de categorÃ­as, lo que permitiÃ³ clasificar las variables segÃºn su nivel de complejidad y definir una estrategia diferenciada para cada grupo. Â 

A partir de allÃ­, se diseÃ±aron tres experimentos independientes (Label, One-Hot y Target Encoding) bajo un esquema controlado, utilizando las mismas mÃ©tricas, modelo base y divisiÃ³n de datos para asegurar una comparaciÃ³n justa. Â 
Cada pipeline fue implementado dentro de un `ColumnTransformer`, lo que permitiÃ³ **modularizar las transformaciones** y mantener un flujo reproducible. Â 

En el caso del *Target Encoding*, se aplicÃ³ validaciÃ³n cruzada (*KFold*) para prevenir fugas de informaciÃ³n entre conjuntos de entrenamiento y validaciÃ³n. Â 
El parÃ¡metro de *smoothing* se calibrÃ³ para equilibrar la estabilidad de las medias y la variabilidad de las categorÃ­as menos frecuentes. Â 

Finalmente, los resultados de cada tÃ©cnica fueron integrados y analizados con herramientas de interpretabilidad (*feature importance* y *SHAP*), lo que permitiÃ³ cuantificar el efecto del encoding sobre la relevancia y comportamiento de las variables dentro del modelo. Â 
El pipeline resultante demostrÃ³ la importancia de **elegir la tÃ©cnica adecuada segÃºn la naturaleza de cada variable**, optimizando asÃ­ la precisiÃ³n sin comprometer la escalabilidad ni la claridad del modelo.

---

## Evidencias Â 

### Cardinalidad de Variables CategÃ³ricas
![Cardinalidad de Variables CategÃ³ricas](IMG_4254.png) Â 
Se visualiza la cantidad de categorÃ­as Ãºnicas por variable, base para definir quÃ© variables se tratan con One-Hot Encoding (baja cardinalidad) y cuÃ¡les requieren Target Encoding (alta cardinalidad).

### DistribuciÃ³n de Education segÃºn nivel de ingreso
![DistribuciÃ³n Education](IMG_4326.png) Â 
Permite observar la relaciÃ³n entre nivel educativo y probabilidad de superar los $50K, destacando la diferencia entre niveles secundarios y universitarios.

### DistribuciÃ³n de Occupation segÃºn nivel de ingreso
![DistribuciÃ³n Occupation](IMG_4261.png) Â 
Muestra las ocupaciones mÃ¡s asociadas con ingresos altos, destacando la brecha entre categorÃ­as profesionales y de servicio.

### DistribuciÃ³n de Relationship segÃºn nivel de ingreso
![DistribuciÃ³n Relationship](IMG_4262.png) Â 
ComparaciÃ³n de tipos de relaciÃ³n familiar frente al nivel de ingreso, evidenciando patrones significativos en el grupo â€œHusbandâ€.

### Matriz de Correlaciones â€“ Variables numÃ©ricas y target
![Matriz de Correlaciones NumÃ©ricas](IMG_4258.png) Â 
Correlaciones entre variables numÃ©ricas y la variable objetivo; se destacan `education-num`, `age` y `capital-gain` como las mÃ¡s relevantes.

### Matriz de Correlaciones (Top variables por relaciÃ³n con el target)
![Matriz de Correlaciones Top](IMG_4328.png) Â 
Refina el anÃ¡lisis mostrando solo las variables con mayor peso predictivo sobre el target, Ãºtil para priorizar en la etapa de feature selection.

### Importancia de Features â€“ Modelo Final
![Top 15 Features mÃ¡s importantes](IMG_4257.png) Â 
Ranking de las 15 variables mÃ¡s influyentes segÃºn el modelo final (Random Forest con pipeline), seÃ±alando la relevancia de `fnlwgt`, `age` y `education-num`.

### Importancia y DistribuciÃ³n de Features
![DistribuciÃ³n Importancia de Features](IMG_4320.png) Â 
ComparaciÃ³n entre la importancia media y la dispersiÃ³n de variables en el modelo, identificando las que aportan mÃ¡s valor explicativo.

### ComparaciÃ³n de Modelos y CodificaciÃ³n
![ComparaciÃ³n de Modelos y Encoding](IMG_4252.png) Â 
ComparaciÃ³n global entre Label, One-Hot, Target y Pipeline mixto en mÃ©tricas de Accuracy, AUC-ROC, F1, tiempo de entrenamiento y dimensionalidad. Â 
Evidencia que el enfoque mixto logra el mejor equilibrio entre precisiÃ³n y eficiencia.

### InterpretaciÃ³n General

El anÃ¡lisis visual permite comprender cÃ³mo las variables numÃ©ricas y categÃ³ricas influyen en el nivel de ingresos de las personas segÃºn el Censo de EE.UU. (1994). Â 
Se observa que **edad, educaciÃ³n y capital-gain** son los predictores mÃ¡s relevantes, mientras que las variables categÃ³ricas como **ocupaciÃ³n, estado civil y relaciÃ³n familiar** tambiÃ©n aportan poder explicativo significativo tras aplicar tÃ©cnicas de codificaciÃ³n adecuadas.

El uso combinado de **One-Hot Encoding** para variables de baja cardinalidad y **Target Encoding** para las de alta cardinalidad permitiÃ³ reducir la dimensionalidad sin perder desempeÃ±o. Â 
El modelo final logrÃ³ un equilibrio entre **precisiÃ³n y eficiencia**, demostrando la importancia de un diseÃ±o de pipeline estratÃ©gico para datos reales con gran diversidad de categorÃ­as.

---

## Insights clave Â 

- El *feature encoding* es una etapa determinante para la **eficiencia y generalizaciÃ³n** del modelo. Â 
- El *Label Encoding* resulta adecuado solo para algoritmos basados en Ã¡rboles, donde la jerarquÃ­a numÃ©rica no induce sesgos. Â 
- El *One-Hot Encoding* mantiene interpretabilidad, pero **penaliza la dimensionalidad**, especialmente en variables con alta cardinalidad. Â 
- El *Target Encoding*, correctamente implementado con *cross-validation*, logra **mejor precisiÃ³n y estabilidad**, evitando fugas de informaciÃ³n. Â 
- Los *pipelines hÃ­bridos* permiten integrar mÃºltiples mÃ©todos segÃºn la naturaleza de las variables, optimizando la relaciÃ³n entre complejidad y desempeÃ±o. Â 
- Las mÃ©tricas obtenidas y el anÃ¡lisis con *SHAP* demostraron que la codificaciÃ³n influye directamente en la **importancia relativa de las variables** y en la transparencia del modelo.

---

## ReflexiÃ³n Â 

Esta prÃ¡ctica permitiÃ³ comprender el **rol crÃ­tico del encoding categÃ³rico** como puente entre los datos reales y la capacidad predictiva de los modelos. Â 
El proceso evidenciÃ³ que la calidad de la representaciÃ³n de las variables categÃ³ricas **determina en gran medida la precisiÃ³n, la interpretabilidad y la eficiencia computacional** del modelo final. Â 

La comparaciÃ³n de tÃ©cnicas mostrÃ³ que no existe un mÃ©todo universalmente superior: cada enfoque presenta **trade-offs especÃ­ficos** entre complejidad, escalabilidad y robustez. Â 
El *Target Encoding* se destacÃ³ por su balance entre poder predictivo y control de dimensionalidad, siempre que se aplique con mecanismos de validaciÃ³n que eviten *data leakage*. Â 

Desde una perspectiva de ingenierÃ­a de datos, la prÃ¡ctica reafirma que **las decisiones tomadas en la etapa de preparaciÃ³n son tan importantes como la elecciÃ³n del modelo en sÃ­**, y que un pipeline bien diseÃ±ado puede marcar la diferencia entre un modelo funcional y uno verdaderamente confiable. Â 

En sÃ­ntesis, el *feature encoding* se consolida como una fase estratÃ©gica del proceso analÃ­tico: **transforma la informaciÃ³n categÃ³rica del mundo real en representaciones matemÃ¡ticas que los algoritmos pueden entender, sin perder su significado original.**

---

## Notebook en Google Colab Â 
ğŸ““ El notebook completo con el desarrollo de esta prÃ¡ctica puede consultarse en el siguiente enlace: Â 
[Abrir en Google Colab](https://colab.research.google.com/github/Agustina-Esquibel/Ingenieria-datos/blob/main/docs/UT3/practica9/UT3_Practica9.ipynb)

---

## Referencias oficiales Â 
- [Category Encoders Library](https://contrib.scikit-learn.org/category_encoders/) Â 
- [Scikit-learn Preprocessing Documentation](https://scikit-learn.org/stable/modules/preprocessing.html) Â 
- [Feature Engineering for Machine Learning â€“ Oâ€™Reilly, Cap. 5](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/) Â 
- [Kaggle Feature Engineering â€“ Target Encoding Guide](https://www.kaggle.com/code/ryanholbrook/target-encoding) Â 

---

## NavegaciÃ³n Â 
â¬…ï¸ [DiseÃ±ando el valor oculto: cÃ³mo el feature engineering mejora la predicciÃ³n de precios de vivienda](../practica8/main8.md) Â 

â¡ï¸ [Reduciendo el ruido: cÃ³mo PCA y Feature Selection revelan las variables clave del valor inmobiliario](../practica10/main10.md) Â 

ğŸ““ [Ãndice del Portafolio](../../portfolio/index.md)
