---
title: "DiseÃ±ando el valor oculto: cÃ³mo el feature engineering mejora la predicciÃ³n de precios de vivienda"
date: 2025-10-01
---

## Contexto
Esta prÃ¡ctica se enfoca en el proceso de **feature engineering** aplicado a un caso de negocio inmobiliario. Â 
El objetivo es comprender cÃ³mo la creaciÃ³n de **nuevas variables derivadas e interacciones** mejora la capacidad predictiva de los modelos de precios de vivienda, utilizando primero un **dataset sintÃ©tico** y luego validando los resultados con una muestra reducida del dataset real **Ames Housing**. Â 

El enfoque combina la **experimentaciÃ³n tÃ©cnica** con el **conocimiento del dominio**, demostrando que el diseÃ±o de variables relevantes puede transformar datos estructurales simples en informaciÃ³n estratÃ©gica **capaz de optimizar decisiones de valuaciÃ³n y predicciÃ³n en el mercado inmobiliario.**

---

## Objetivos Â 
- Aplicar un flujo completo de **feature engineering** con datos simulados y reales. Â 
- Generar nuevas **features derivadas** y de **interacciÃ³n** que representen comportamientos reales del mercado inmobiliario. Â 
- Analizar la **distribuciÃ³n, correlaciÃ³n e importancia** de las nuevas variables. Â 
- Evaluar el impacto predictivo de las features mediante mÃ©tricas estadÃ­sticas y modelos de *machine learning*, validando los resultados con una muestra del dataset **Ames Housing**.

---

## Actividades Â 

La prÃ¡ctica comenzÃ³ con la preparaciÃ³n del entorno en Google Colab y la carga de las librerÃ­as necesarias (`pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn`). Para facilitar la experimentaciÃ³n, se construyÃ³ primero un **dataset sintÃ©tico de viviendas**, incorporando variables como superficie, precio, cantidad de habitaciones, baÃ±os, tamaÃ±o del lote, aÃ±o de construcciÃ³n, distancia al centro, rating escolar, criminalidad y garaje. Este enfoque permitiÃ³ probar transformaciones de forma controlada antes de pasar a datos reales.

Sobre esta base se desarrollÃ³ un conjunto amplio de **features derivadas** vinculadas a eficiencia del espacio, escalas y proporciones: `price_per_sqft`, `log_price`, `sqft_per_bedroom`, `density`, `bed_bath_ratio`, `price_per_bedroom`, `lot_coverage`, `bedrooms_per_1000sqft`, junto con variables temporales como `property_age`, `age_category`, `is_new_property` y `decade_built`. Estas transformaciones permitieron capturar patrones estructurales asociados al espacio disponible, la distribuciÃ³n interna y la antigÃ¼edad de las propiedades.

Luego se realizÃ³ un **anÃ¡lisis de distribuciÃ³n y correlaciones**, donde se identificaron relaciones clave consistentes con las visualizaciones obtenidas: Â 
- una correlaciÃ³n negativa entre eficiencia espacial y densidad interna (`efficiency_score` vs `density` = -0.42), Â 
- una correlaciÃ³n negativa entre calidad percibida y antigÃ¼edad de la vivienda (`quality_indicator` vs `property_age` = -0.56). Â 

TambiÃ©n se exploraron relaciones entre precio, superficie, antigÃ¼edad y distancia al centro, evidenciando diferencias esperables entre viviendas nuevas, modernas y antiguas.

La contribuciÃ³n de cada *feature* se evaluÃ³ utilizando **Mutual Information** y **Random Forest Feature Importance**. En ambos casos, las variables mÃ¡s influyentes fueron `log_price` y `price_per_sqft`, seguidas por indicadores de eficiencia y distribuciÃ³n como `density`, `sqft_per_bedroom` y transformaciones matemÃ¡ticas (`sqrt_sqft`, `sqft_squared`). Estas conclusiones coinciden con los grÃ¡ficos de importancia generados.

Como parte del componente investigativo, se incorporaron **features de dominio inmobiliario** tales como:
- `space_efficiency` (relaciÃ³n superficie/lote), Â 
- `crowded_property` (densidad interna), Â 
- `advanced_location_score` (distancia, rating escolar y criminalidad). Â 

TambiÃ©n se diseÃ±aron **features de interacciÃ³n**, incluyendo `price_age_interaction`, `new_large_property` y `distance_school_interaction`. Su impacto se evaluÃ³ mediante correlaciones, destacÃ¡ndose el caso de `price_age_interaction` (correlaciÃ³n â‰ˆ 0.163), coherente con la idea de que las propiedades nuevas sostienen mejor su precio relativo.

Finalmente, el pipeline completo se aplicÃ³ a una muestra del dataset real **Ames Housing**, verificando que las transformaciones fueran consistentes, reproducibles y mantuvieran relevancia predictiva en un contexto mÃ¡s complejo, consolidando un flujo de *feature engineering* robusto y alineado con el caso de negocio. Â 

---

## Desarrollo Â 

El desarrollo se llevÃ³ a cabo de forma incremental, comenzando con la creaciÃ³n de un entorno controlado para experimentar con distintas estrategias de *feature engineering*. Â 
El cÃ³digo se estructurÃ³ en celdas secuenciales dentro de Google Colab, facilitando la trazabilidad de cada etapa del flujo de trabajo. Â 

Primero, se construyÃ³ un **dataset sintÃ©tico** para aislar variables y probar transformaciones sin interferencias externas. Â 
Este enfoque permitiÃ³ **validar el comportamiento de cada feature en condiciones controladas** antes de incorporar la complejidad de un dataset real. Â 

Sobre esta base se aplicaron operaciones matemÃ¡ticas, logarÃ­tmicas y proporcionales para crear nuevas variables, priorizando aquellas que representaran relaciones interpretables entre los datos (eficiencia del espacio, densidad habitacional o relaciÃ³n entre antigÃ¼edad y precio). Â 

El anÃ¡lisis estadÃ­stico se complementÃ³ con visualizaciones generadas en `seaborn` y `matplotlib`, empleadas para inspeccionar distribuciones, correlaciones y presencia de valores atÃ­picos. Â 
Los cÃ¡lculos de *Mutual Information* y *Random Forest Feature Importance* se implementaron en `scikit-learn` para cuantificar la relevancia de cada variable y validar la contribuciÃ³n de las features derivadas. Â 

Finalmente, se abordaron los **DesafÃ­os de creaciÃ³n de nuevas variables**, integrando conocimiento del dominio inmobiliario. Â 
Cada feature fue diseÃ±ada, testeada y evaluada de forma individual antes de incorporarse al conjunto final, consolidando un pipeline iterativo, escalable y consistente con los objetivos del caso.

---

## Evidencias

### DistribuciÃ³n logarÃ­tmica del precio Â 
![DistribuciÃ³n logarÃ­tmica del precio](../practica8/IMG_4228.png) Â 
La transformaciÃ³n logarÃ­tmica del precio reduce la asimetrÃ­a de la distribuciÃ³n, generando una forma mÃ¡s cercana a la normal. Esto mejora la estabilidad de los modelos lineales y evita el sesgo hacia propiedades con precios extremos.


### Precio por mÂ² segÃºn vecindario Â 
![Precio por mÂ² segÃºn vecindario](../practica8/IMG_4229.png) Â 
Los vecindarios muestran diferencias marcadas en el precio por metro cuadrado. â€œNoRidgeâ€ y â€œMitchelâ€ presentan los valores mÃ¡s altos, lo que refleja la influencia del contexto geogrÃ¡fico sobre el valor de las viviendas.


### Distribuciones de nuevas features derivadas Â 
![Distribuciones de nuevas features derivadas](../practica8/IMG_4230.png) Â 
Las features derivadas como `space_efficiency`, `crowded_property` y `distance_school_interaction` presentan distribuciones asimÃ©tricas. Esto sugiere la presencia de propiedades extremas y la necesidad de escalado o transformaciÃ³n antes del modelado.

---

### Importancia de features Â 
![Importancia de features](../practica8/IMG_4231.png) Â 
Tanto la informaciÃ³n mutua como el modelo Random Forest destacan `log_price` y `price_per_sqft` como las variables mÃ¡s influyentes. Esto valida su peso en la predicciÃ³n y sugiere una relaciÃ³n no lineal con la variable objetivo.


### Correlaciones entre features derivadas Â 
![Correlaciones entre features derivadas](../practica8/IMG_4236.png) Â 
Se observa correlaciÃ³n moderada negativa entre `quality_indicator` y `property_age`, lo cual indica que las propiedades mÃ¡s antiguas tienden a tener menor calidad percibida. Las demÃ¡s variables mantienen independencia relativa, Ãºtil para evitar multicolinealidad.


### RelaciÃ³n suavizada: Precio vs Distancia al centro Â 
![RelaciÃ³n suavizada: Precio vs Distancia al centro](../practica8/IMG_4238.png) Â 
Las viviendas nuevas muestran precios mÃ¡s altos en todas las distancias, mientras que las antiguas pierden valor conforme se alejan del centro urbano. Esta tendencia respalda la relevancia de la variable `distance_to_city` como factor de ubicaciÃ³n.

---

## Insights clave Â 

- El **feature engineering transforma datos bÃ¡sicos en conocimiento aplicable**, mejorando la capacidad predictiva y explicativa. Â 
- Las variables **de dominio** aportan valor aÃ±adido al incorporar aspectos contextuales (ubicaciÃ³n, antigÃ¼edad, eficiencia). Â 
- `log_price` y `price_per_sqft` se consolidaron como **indicadores robustos del valor real del inmueble**. Â 
- Las correlaciones entre edad, calidad y eficiencia refuerzan la relaciÃ³n entre modernizaciÃ³n y valorizaciÃ³n. Â 
- El proceso demostrÃ³ que integrar razonamiento tÃ©cnico y conocimiento de negocio **potencia la capacidad interpretativa de los modelos**.

---

## ReflexiÃ³n
Esta prÃ¡ctica confirmÃ³ que el valor de los datos **no reside en su forma original, sino en cÃ³mo se transforman para revelar conocimiento Ãºtil**. Â 
El **feature engineering** se consolida como una de las etapas mÃ¡s crÃ­ticas del flujo de ciencia de datos, donde confluyen **creatividad, rigurosidad estadÃ­stica e interpretabilidad**. Â 

DiseÃ±ar nuevas variables con base en sentido del negocio y evidencia empÃ­rica permite **incrementar la capacidad predictiva de los modelos** sin sacrificar su transparencia. Â 
Asimismo, se evidenciÃ³ que **un exceso de transformaciones puede inducir sobreajuste**, por lo que la selecciÃ³n de features debe fundamentarse en mÃ©tricas objetivas como *mutual information* y *feature importance*. Â 

En sÃ­ntesis, esta prÃ¡ctica permitiÃ³ comprender que la ingenierÃ­a de atributos es tanto un arte como una ciencia: **convierte datos crudos en conocimiento accionable**, y refuerza que el verdadero valor de la ingenierÃ­a de datos radica en su capacidad para **convertir complejidad en claridad, y datos en decisiones.**

---

## Notebook en Google Colab Â 
ğŸ““ El notebook completo con el desarrollo de esta prÃ¡ctica puede consultarse en el siguiente enlace: Â 
[Abrir en Google Colab](https://colab.research.google.com/github/Agustina-Esquibel/Ingenieria-datos/blob/main/docs/UT3/practica8/UT3_Practica_8.ipynb)

---

## ğŸ”— Referencias Â 
- [Feature Selection â€“ Scikit-learn Documentation](https://scikit-learn.org/stable/modules/feature_selection.html) Â 
- [Feature Engineering for Machine Learning â€“ Oâ€™Reilly](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/) Â 

---

## NavegaciÃ³n Â 
â¬…ï¸ [Volver a Unidad TemÃ¡tica 3](../main.md) Â 
â¡ï¸ [Codificando la realidad: cÃ³mo el encoding categÃ³rico mejora la predicciÃ³n de ingresos en datos del censo](../practica9/main9.md) Â 
ğŸ““ [Ãndice del Portafolio](../../portfolio/index.md)
