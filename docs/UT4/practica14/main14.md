---
title: "Escuchando los datos: c√≥mo el preprocesamiento de audio prepara se√±ales crudas para el machine learning"
date: 2025-10-01
---

## Contexto
Esta pr√°ctica forma parte de la Unidad Tem√°tica 4, enfocada en el procesamiento de **datos no tradicionales**, espec√≠ficamente **audio** como fuente de informaci√≥n.  
El objetivo general es comprender c√≥mo una se√±al sonora en bruto puede transformarse en una representaci√≥n num√©rica √∫til mediante un pipeline estructurado de **preprocesamiento, visualizaci√≥n, filtrado, augmentaci√≥n y extracci√≥n de features**.

El enfoque combina t√©cnicas de **procesamiento digital de se√±ales** con principios de **feature engineering**, demostrando que la calidad y coherencia del pipeline influyen directamente en la robustez de los futuros modelos de machine learning.

---

## Objetivos
- Construir un pipeline reproducible de **preprocesamiento de audio** utilizando `librosa`, `numpy`, `matplotlib` y `scipy`.
- Analizar la se√±al en el **dominio temporal** (waveform) y en el **dominio frecuencial** (espectrograma).
- Aplicar transformaciones que mejoran la calidad de la se√±al: **estandarizaci√≥n, ruido controlado, filtrado high-pass**.
- Calcular **m√©tricas espectrales din√°micas** (centroid, rolloff, bandwidth).
- Implementar **data augmentation** mediante *pitch shift* y *time stretching*.
- Extraer **MFCC** y generar un archivo **CSV de features** apto para modelos supervisados.

---

## Desarrollo

### 1. Carga y estandarizaci√≥n del audio
El estudiante carg√≥ los clips WAV utilizando `librosa.load`, aplicando dos configuraciones clave:

- **Resampleo a 16 kHz**, frecuencia suficiente para voz y sonidos urbanos, que adem√°s reduce tama√±o y estandariza los clips.
- **Conversi√≥n a mono**, simplificando el an√°lisis y evitando duplicaci√≥n de informaci√≥n estereof√≥nica irrelevante para este contexto.

Posteriormente se grafic√≥ la **forma de onda** y se aplic√≥ una **estandarizaci√≥n z-score**, centrando la se√±al en cero y homogeneizando la escala para evitar que diferencias de volumen afecten el an√°lisis o el rendimiento de futuros modelos.

---

### 2. Espectrograma de potencia
Se implement√≥ una funci√≥n personalizada para calcular espectrogramas utilizando STFT con:

- `n_fft = 2048`  
- `hop_length = 512`

Estos par√°metros equilibran la resoluci√≥n temporal y frecuencial, adecuados para an√°lisis exploratorio.

Se compararon espectrogramas del **audio original** y del **audio estandarizado**, verificando que la estructura espectral se conserva mientras la escala se normaliza.

---

### 3. Ruido y relaci√≥n se√±al-ruido (SNR)
Se a√±adi√≥ **ruido blanco** con SNR = **10 dB** para simular condiciones reales de grabaci√≥n (ambientes urbanos, micr√≥fonos m√≥viles) y observar c√≥mo cambia la representaci√≥n espectral bajo ruido controlado.

Esta etapa permiti√≥ evaluar la robustez de la se√±al y analizar qu√© estructuras del audio permanecen visibles a√∫n con interferencia significativa.

---

### 4. Filtrado High-Pass
Se aplic√≥ un filtro **Butterworth de orden 4** con corte en **80 Hz** para eliminar componentes graves no informativos.

El espectrograma posterior mostr√≥ una reducci√≥n marcada de energ√≠a en bajas frecuencias, confirmando que el filtrado retira ruido sin comprometer informaci√≥n relevante para tareas de clasificaci√≥n.

---

### 5. M√©tricas espectrales adicionales
Se calcularon las m√©tricas:

- **Spectral centroid**  
- **Spectral rolloff (p85)**  
- **Spectral bandwidth**

Estas series temporales ofrecen una representaci√≥n compacta del comportamiento espectral, permitiendo detectar variaciones en brillo, distribuci√≥n de energ√≠a y amplitud de banda a lo largo del tiempo.

---

### 6. An√°lisis del dataset
Se gener√≥ un gr√°fico que muestra la **cantidad de audios por fold**, lo cual permiti√≥ identificar desbalances en la distribuci√≥n del dataset.

Estos desbalances son relevantes para modelado posterior, ya que pueden requerir estrategias de compensaci√≥n o augmentaci√≥n adicional.

---

### 7. Data Augmentation
Se aplicaron dos t√©cnicas:

- **Pitch shift (+2 semitonos)**  
- **Time stretching (0.9x)**  

Estas transformaciones producen variantes realistas del audio original, suficientes para aumentar la diversidad del dataset sin perder coherencia perceptual. Esto contribuye a mejorar la generalizaci√≥n de modelos en escenarios de entrenamiento con pocos ejemplos.

---

### 8. Extracci√≥n de MFCC
Finalmente, se extrajeron **coeficientes MFCC** y se calcularon estad√≠sticos agregados por clip.  
El resultado se almacen√≥ en un **archivo CSV** que resume cada audio como un vector de caracter√≠sticas, permitiendo entrenar modelos supervisados sin reprocesar la se√±al original.

---

## Evidencias

### Waveform del audio original  
![IMG_4785](IMG_4785.png)  
Esta visualizaci√≥n muestra la forma de onda en dominio temporal, permitiendo observar la amplitud y la distribuci√≥n de energ√≠a del audio crudo. Se identifican picos, zonas m√°s densas y variaciones de intensidad que son clave para anticipar la calidad del preprocesamiento y analizar la din√°mica del sonido antes de aplicar transformaciones.

---

### Waveform original vs estandarizado  
![IMG_4786](IMG_4786.png)  
Comparar la se√±al sin procesar con la versi√≥n estandarizada permite evaluar c√≥mo la normalizaci√≥n modifica la escala, eliminando sesgos de amplitud que podr√≠an afectar la extracci√≥n de features. La estandarizaci√≥n aporta estabilidad al pipeline al equilibrar la energ√≠a entre audios heterog√©neos.

---

### Espectrograma original (mono)  
![IMG_4787](IMG_4787.png)  
El espectrograma representa la distribuci√≥n de energ√≠a a trav√©s del tiempo y la frecuencia. En esta versi√≥n original se aprecia el patr√≥n frecuencial sin modificaciones, fundamental como referencia para comparar efectos de filtros, normalizaciones y ruido.

---

### Espectrograma estandarizado  
![IMG_4788](IMG_4788.png)  
La estandarizaci√≥n suaviza el rango din√°mico del espectrograma, aumentando la claridad de los patrones espectrales y reduciendo variaciones abruptas. Esto facilita que los modelos interpreten texturas con mayor consistencia.

---

### Espectrograma con ruido blanco (SNR‚âà10 dB)  
![IMG_4789](IMG_4789.png)  
La incorporaci√≥n de ruido blanco permite evaluar la **robustez del pipeline** ante degradaciones reales. Se observa una textura m√°s densa y homog√©nea, que desaf√≠a la detecci√≥n de features y sirve como prueba de estr√©s para el modelo.

---

### Espectrograma tras filtro high-pass (80 Hz)  
![IMG_4790](IMG_4790.png)  
Este espectrograma evidencia c√≥mo el filtro elimina componentes de muy baja frecuencia, limpiando el espectro y haciendo m√°s visibles los patrones relevantes. Es √∫til para reducir ruido de fondo y vibraciones de baja frecuencia.

---

### M√©tricas espectrales din√°micas  
![IMG_4791](IMG_4791.png)  
Se monitorean **centroid**, **rolloff** y **bandwidth**, tres m√©tricas cr√≠ticas para caracterizar la firma espectral del audio. Su estabilidad a lo largo del tiempo indica consistencia en la se√±al, lo cual es clave para tareas de clasificaci√≥n o identificaci√≥n.

---

### Cantidad de audios por fold  
![IMG_4792](IMG_4792.png)  
Este gr√°fico verifica que la divisi√≥n en folds mantiene un balance correcto. Asegurar proporciones estables evita sesgos en validaci√≥n cruzada y garantiza resultados reproducibles.

---

### Pitch shift +2 semitonos  
![IMG_4793](IMG_4793.png)  
El aumento de pitch desplaza la energ√≠a hacia frecuencias m√°s altas sin modificar la duraci√≥n. Es una de las t√©cnicas m√°s utilizadas en **data augmentation**, particularmente en tareas de reconocimiento de voz o clasificaci√≥n de audio.

---

### Time stretch 0.9x  
![IMG_4794](IMG_4794.png)  
La compresi√≥n temporal modifica la densidad de eventos en el espectrograma. Este tipo de transformaci√≥n eval√∫a si el modelo puede generalizar ante cambios de velocidad en la se√±al, algo crucial en datasets con habla o sonidos variables.

---

### Efecto del SNR sobre el RMS  
![IMG_4795](IMG_4795.png)  
El gr√°fico muestra c√≥mo la energ√≠a del audio disminuye al introducir m√°s ruido blanco. Esta relaci√≥n inversa confirma la sensibilidad del RMS como m√©trica para evaluar degradaciones y sirve para ajustar umbrales de detecci√≥n.

---

### Comparaci√≥n simple de pipelines  
![IMG_4796](IMG_4796.png)  
La comparaci√≥n de pipelines mediante **RMS mean** y **ZCR mean** permite entender qu√© transformaciones preservan informaci√≥n relevante y cu√°les introducen distorsiones. Es una herramienta esencial en la etapa de selecci√≥n del preprocesamiento √≥ptimo.

---

### M√©tricas principales del audio (Duraci√≥n, RMS, ZCR)  
![IMG_4797](IMG_4797.png)  
Estas m√©tricas resumen las propiedades globales del audio. La homogeneidad en duraci√≥n y los valores consistentes en RMS y ZCR confirman que el dataset es adecuado para an√°lisis comparativos y para alimentar modelos supervisados sin introducir variabilidad no deseada.

---

## Insights clave
- El preprocesamiento de audio transforma se√±ales crudas en datos estables y comparables.  
- Los espectrogramas permiten detectar patrones, ruidos y problemas de calidad imposibles de visualizar en el waveform.  
- La estandarizaci√≥n y el filtrado high-pass mejoran la legibilidad y reducen variabilidad irrelevante.  
- Las m√©tricas espectrales din√°micas proporcionan indicadores compactos para an√°lisis avanzados.  
- La data augmentation en audio permite ampliar la diversidad del dataset sin necesidad de nuevas grabaciones.  
- Los MFCC act√∫an como puente entre la se√±al de audio y los modelos cl√°sicos de machine learning.

---

## Reflexi√≥n
La pr√°ctica evidenci√≥ que el audio, aunque inicialmente complejo, puede convertirse en un tipo de dato completamente estructurado mediante un pipeline de preprocesamiento bien dise√±ado.  
Cada transformaci√≥n ‚Äîresampleo, estandarizaci√≥n, ruido, filtrado, augmentaci√≥n‚Äî afecta de forma directa la robustez del modelo y la calidad de los features extra√≠dos.

El trabajo refuerza la importancia de combinar fundamentos de procesamiento digital de se√±ales con principios de ingenier√≠a de datos.  
En s√≠ntesis, esta pr√°ctica demuestra que **la representaci√≥n correcta del audio determina el √©xito de su an√°lisis**, y que un pipeline s√≥lido es clave para integrar sonidos en proyectos de anal√≠tica avanzada.

---
## Notebook en Google Colab

üìì El notebook completo con el desarrollo de esta pr√°ctica puede consultarse en el siguiente enlace:

üîó [Abrir en Google Colab](https://colab.research.google.com/github/Agustina-Esquibel/Ingenieria-datos/blob/main/docs/UT4/practica14/UT4Practica14.ipynb)

---

## üîó Referencias
- McFee et al. (2015). *librosa: Audio and Music Signal Analysis in Python*.  
- Documentaci√≥n oficial de Librosa: https://librosa.org/doc  
- Material de la c√°tedra ‚Äì UT4 Audio como dato: https://juanfkurucz.com/ucu-id/ut4/14-audio/  
- Smith, J.O. *Spectrograms and Time-Frequency Analysis.*

---

## Navegaci√≥n
‚¨ÖÔ∏è [Volver a Unidad Tem√°tica 4](../main.md)  
‚û°Ô∏è [Pr√°ctica 15 ‚Äì (si aplica)](#)  
üìì [√çndice del Portafolio](../../portfolio/index.md)
