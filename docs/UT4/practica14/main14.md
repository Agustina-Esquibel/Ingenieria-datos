---
title: "Escuchando los datos: c√≥mo el preprocesamiento de audio prepara se√±ales crudas para el machine learning"
date: 2025-10-01
---

## Contexto
Esta pr√°ctica forma parte de la Unidad Tem√°tica 4, enfocada en el procesamiento de **datos no tradicionales**, espec√≠ficamente **audio** como fuente de informaci√≥n.  
El objetivo general es comprender c√≥mo una se√±al sonora en bruto puede transformarse en una representaci√≥n num√©rica √∫til mediante un pipeline estructurado de **preprocesamiento, visualizaci√≥n, filtrado, augmentaci√≥n y extracci√≥n de features**.

El enfoque combina t√©cnicas de **procesamiento digital de se√±ales** con principios de **feature engineering**, demostrando que la calidad y coherencia del pipeline influyen directamente en la robustez de los futuros modelos de machine learning.

---

## Objetivos
- Construir un pipeline reproducible de **preprocesamiento de audio** utilizando `librosa`, `numpy`, `matplotlib` y `scipy`.
- Analizar la se√±al en el **dominio temporal** (waveform) y en el **dominio frecuencial** (espectrograma).
- Aplicar transformaciones que mejoran la calidad de la se√±al: **estandarizaci√≥n, ruido controlado, filtrado high-pass**.
- Calcular **m√©tricas espectrales din√°micas** (centroid, rolloff, bandwidth).
- Implementar **data augmentation** mediante *pitch shift* y *time stretching*.
- Extraer **MFCC** y generar un archivo **CSV de features** apto para modelos supervisados.

---

## Desarrollo

### 1. Carga y estandarizaci√≥n del audio
El estudiante carg√≥ los clips WAV utilizando `librosa.load`, aplicando dos configuraciones clave:

- **Resampleo a 16 kHz**, frecuencia suficiente para voz y sonidos urbanos, que adem√°s reduce tama√±o y estandariza los clips.
- **Conversi√≥n a mono**, simplificando el an√°lisis y evitando duplicaci√≥n de informaci√≥n estereof√≥nica irrelevante para este contexto.

Posteriormente se grafic√≥ la **forma de onda** y se aplic√≥ una **estandarizaci√≥n z-score**, centrando la se√±al en cero y homogeneizando la escala para evitar que diferencias de volumen afecten el an√°lisis o el rendimiento de futuros modelos.

---

### 2. Espectrograma de potencia
Se implement√≥ una funci√≥n personalizada para calcular espectrogramas utilizando STFT con:

- `n_fft = 2048`  
- `hop_length = 512`

Estos par√°metros equilibran la resoluci√≥n temporal y frecuencial, adecuados para an√°lisis exploratorio.

Se compararon espectrogramas del **audio original** y del **audio estandarizado**, verificando que la estructura espectral se conserva mientras la escala se normaliza.

---

### 3. Ruido y relaci√≥n se√±al-ruido (SNR)
Se a√±adi√≥ **ruido blanco** con SNR = **10 dB** para simular condiciones reales de grabaci√≥n (ambientes urbanos, micr√≥fonos m√≥viles) y observar c√≥mo cambia la representaci√≥n espectral bajo ruido controlado.

Esta etapa permiti√≥ evaluar la robustez de la se√±al y analizar qu√© estructuras del audio permanecen visibles a√∫n con interferencia significativa.

---

### 4. Filtrado High-Pass
Se aplic√≥ un filtro **Butterworth de orden 4** con corte en **80 Hz** para eliminar componentes graves no informativos.

El espectrograma posterior mostr√≥ una reducci√≥n marcada de energ√≠a en bajas frecuencias, confirmando que el filtrado retira ruido sin comprometer informaci√≥n relevante para tareas de clasificaci√≥n.

---

### 5. M√©tricas espectrales adicionales
Se calcularon las m√©tricas:

- **Spectral centroid**  
- **Spectral rolloff (p85)**  
- **Spectral bandwidth**

Estas series temporales ofrecen una representaci√≥n compacta del comportamiento espectral, permitiendo detectar variaciones en brillo, distribuci√≥n de energ√≠a y amplitud de banda a lo largo del tiempo.

---

### 6. An√°lisis del dataset
Se gener√≥ un gr√°fico que muestra la **cantidad de audios por fold**, lo cual permiti√≥ identificar desbalances en la distribuci√≥n del dataset.

Estos desbalances son relevantes para modelado posterior, ya que pueden requerir estrategias de compensaci√≥n o augmentaci√≥n adicional.

---

### 7. Data Augmentation
Se aplicaron dos t√©cnicas:

- **Pitch shift (+2 semitonos)**  
- **Time stretching (0.9x)**  

Estas transformaciones producen variantes realistas del audio original, suficientes para aumentar la diversidad del dataset sin perder coherencia perceptual. Esto contribuye a mejorar la generalizaci√≥n de modelos en escenarios de entrenamiento con pocos ejemplos.

---

### 8. Extracci√≥n de MFCC
Finalmente, se extrajeron **coeficientes MFCC** y se calcularon estad√≠sticos agregados por clip.  
El resultado se almacen√≥ en un **archivo CSV** que resume cada audio como un vector de caracter√≠sticas, permitiendo entrenar modelos supervisados sin reprocesar la se√±al original.

---

## Evidencias

### Waveform original y estandarizado  
La estandarizaci√≥n conserva la forma general de la se√±al pero unifica la escala, permitiendo comparar clips sin sesgos de volumen.

---

### Espectrograma de potencia (original vs estandarizado)  
El contenido espectral se mantiene estable tras la estandarizaci√≥n, modific√°ndose √∫nicamente la escala en dB, lo que confirma que el preprocesamiento no altera caracter√≠sticas relevantes del sonido.

---

### Espectrograma con ruido blanco (SNR = 10 dB)  
El ruido incrementa la energ√≠a distribuida en todas las frecuencias, simulando condiciones hostiles de grabaci√≥n. Aun as√≠, las estructuras principales del sonido permanecen visibles.

---

### Espectrograma tras filtro high-pass (80 Hz)  
El filtrado elimina bajas frecuencias asociadas a vibraciones o zumbidos. El contenido informativo permanece intacto.

---

### M√©tricas espectrales din√°micas  
Las curvas de centroid, rolloff y bandwidth condensan la evoluci√≥n del espectro a lo largo del tiempo y facilitan la interpretaci√≥n de la se√±al.

---

### Data Augmentation (pitch shift +2, time stretch 0.9x)  
Las variantes generadas modifican frecuencia o duraci√≥n sin alterar la identidad del sonido, aportando diversidad al conjunto de entrenamiento.

---

## Insights clave
- El preprocesamiento de audio transforma se√±ales crudas en datos estables y comparables.  
- Los espectrogramas permiten detectar patrones, ruidos y problemas de calidad imposibles de visualizar en el waveform.  
- La estandarizaci√≥n y el filtrado high-pass mejoran la legibilidad y reducen variabilidad irrelevante.  
- Las m√©tricas espectrales din√°micas proporcionan indicadores compactos para an√°lisis avanzados.  
- La data augmentation en audio permite ampliar la diversidad del dataset sin necesidad de nuevas grabaciones.  
- Los MFCC act√∫an como puente entre la se√±al de audio y los modelos cl√°sicos de machine learning.

---

## Reflexi√≥n
La pr√°ctica evidenci√≥ que el audio, aunque inicialmente complejo, puede convertirse en un tipo de dato completamente estructurado mediante un pipeline de preprocesamiento bien dise√±ado.  
Cada transformaci√≥n ‚Äîresampleo, estandarizaci√≥n, ruido, filtrado, augmentaci√≥n‚Äî afecta de forma directa la robustez del modelo y la calidad de los features extra√≠dos.

El trabajo refuerza la importancia de combinar fundamentos de procesamiento digital de se√±ales con principios de ingenier√≠a de datos.  
En s√≠ntesis, esta pr√°ctica demuestra que **la representaci√≥n correcta del audio determina el √©xito de su an√°lisis**, y que un pipeline s√≥lido es clave para integrar sonidos en proyectos de anal√≠tica avanzada.

---

## Notebook en Google Colab
üìì El notebook completo puede consultarse en el siguiente enlace:  

---

## üîó Referencias
- McFee et al. (2015). *librosa: Audio and Music Signal Analysis in Python*.  
- Documentaci√≥n oficial de Librosa: https://librosa.org/doc  
- Material de la c√°tedra ‚Äì UT4 Audio como dato: https://juanfkurucz.com/ucu-id/ut4/14-audio/  
- Smith, J.O. *Spectrograms and Time-Frequency Analysis.*

---

## Navegaci√≥n
‚¨ÖÔ∏è [Volver a Unidad Tem√°tica 4](../main.md)  
‚û°Ô∏è [Pr√°ctica 15 ‚Äì (si aplica)](#)  
üìì [√çndice del Portafolio](../../portfolio/index.md)
